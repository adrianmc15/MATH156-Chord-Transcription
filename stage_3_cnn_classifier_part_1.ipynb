{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: CNN Classifier\n",
    "The manual approach, yielded some positive results\n",
    "Let's see if a machine learning algorithm using similar information might also work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plan:**\n",
    "\n",
    "Chord Qualities:\n",
    "1. Compute the summed frequency array, and note bin arrays\n",
    "2. Put these into a CNN (try different combinations)\n",
    "3. Try a few other models, including:\n",
    "    - random forest\n",
    "    - hmm\n",
    "    - knn\n",
    "\n",
    "Root Notes:\n",
    "1. Given the calculated quality and frequency volume, try to work out what the root note is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.io.wavfile import read as read_wav\n",
    "from scipy import fft,signal\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "TONE_A = 440 \n",
    "NOTES = ['A','A#','B','C','C#','D','D#','E','F','F#','G','G#'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_to_rnote(freq):\n",
    "    r = 12.0*np.log2(freq/TONE_A)\n",
    "    return r\n",
    "\n",
    "def rnote_to_freq(r):\n",
    "    f = TONE_A*2**(r/12)\n",
    "    return f\n",
    "\n",
    "def get_note_volume(rnote,fft_image,fft_freq,rnote_epsilon=0.2):\n",
    "    \"\"\" rnote - name or number of note,fft_image - fourier image of signal,\n",
    "    fft_freq - frequencies in fft_image,rnote_epsilon - halfwide of window to inspect\n",
    "    return maximum volume(magnitude) of signal in freq window for rnote \"\"\"\n",
    "    if isinstance(rnote,str):\n",
    "        rnote = NOTES.index(rnote)\n",
    "    try:\n",
    "        f0 = rnote_to_freq(rnote-rnote_epsilon)\n",
    "        f1 = rnote_to_freq(rnote+rnote_epsilon)\n",
    "        f_idx = np.where((fft_freq>=f0)&(fft_freq<=f1)) \n",
    "        maxVol = np.max((fft_image[f_idx]))\n",
    "    except Exception:\n",
    "        return 0.\n",
    "    \n",
    "    return maxVol\n",
    "\n",
    "def get_notes_volume(rnote,fft_image,fft_freq,rnote_epsilon=0.5,oct_range_from=-4.,oct_range_to=8.):\n",
    "    if isinstance(rnote,str):\n",
    "        rnote = NOTES.index(rnote)\n",
    "    rnotes = np.arange(rnote+12.*oct_range_from,rnote+12.*oct_range_to,12.0)\n",
    "    vol = []\n",
    "    for rn in rnotes:\n",
    "        vol.append(get_note_volume(rn,fft_image,fft_freq))\n",
    "        \n",
    "    return np.max(vol)\n",
    "\n",
    "def plot_notes(fileName):\n",
    "    \"\"\"convert the fft image from file to notes notations and plot on\"\"\"\n",
    "    #print(fileName)\n",
    "    rate,data_raw = read_wav(fileName)\n",
    "    data = (data_raw[:,0]+data_raw[:,1]).astype(np.float32) # stereo of any type -> mono of float32\n",
    "    data = minmax_scale(data,(-1.,1.)) \n",
    "    fft_image = np.abs(fft.rfft(data,norm='forward')) \n",
    "    fft_freq = fft.rfftfreq(len(data),1./rate)\n",
    "    vol_matrix = np.ndarray(shape=(12),dtype=np.float32)\n",
    "    for rnote in range(12):\n",
    "        vol_matrix[rnote] = get_notes_volume(rnote,fft_image,fft_freq)\n",
    "        \n",
    "    plt.bar(NOTES, vol_matrix)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    File Path Root Note  Octave Quality  \\\n",
      "0        data/chords/dim/Eb-7-dim-chord-1.wav        Eb       7     dim   \n",
      "1   data/chords/min7b5/C-3-min7b5-chord-1.wav         C       3  min7b5   \n",
      "2       data/chords/dim7/E-6-dim7-chord-0.wav         E       6    dim7   \n",
      "3        data/chords/min/Bb-5-min-chord-0.wav        Bb       5     min   \n",
      "4  data/chords/maj7_2/Ab-5-maj7_2-chord-0.wav        Ab       5  maj7_2   \n",
      "\n",
      "   Inversion  \n",
      "0          1  \n",
      "1          1  \n",
      "2          0  \n",
      "3          0  \n",
      "4          0  \n"
     ]
    }
   ],
   "source": [
    "# try it out on a few of the files in /data/train_set.csv:\n",
    "train_set = pd.read_csv('data/train_set.csv')\n",
    "test_set = pd.read_csv('data/test_set.csv')\n",
    "print(train_set.head())\n",
    "\n",
    "# remove the chords that are not maj or min in the Quality column\n",
    "train_set = train_set[train_set['Quality'].isin(['maj', 'min', 'dim', 'aug'])]\n",
    "test_set = test_set[test_set['Quality'].isin(['maj', 'min', 'dim', 'aug'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         File Path  Root Note  Octave  Inversion\n",
      "Quality                                         \n",
      "aug            179        179     179        179\n",
      "dim            178        178     178        178\n",
      "maj            178        178     178        178\n",
      "min            178        178     178        178\n",
      "         File Path  Root Note  Octave  Inversion\n",
      "Quality                                         \n",
      "aug             76         76      76         76\n",
      "dim             77         77      77         77\n",
      "maj             77         77      77         77\n",
      "min             77         77      77         77\n"
     ]
    }
   ],
   "source": [
    "print(train_set.groupby(['Quality']).count())\n",
    "print(test_set.groupby(['Quality']).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     713\n",
       "unique      4\n",
       "top       aug\n",
       "freq      179\n",
       "Name: Quality, dtype: object"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)\n",
    "# summarise the data\n",
    "train_set['Quality'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 713/713 [00:02<00:00, 297.16it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 314.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# preprocessing:\n",
    "def preprocess(fileName):\n",
    "    rate, data_raw = read_wav(fileName)\n",
    "    data = (data_raw[:,0]+data_raw[:,1]).astype(np.float32) # stereo of any type -> mono of float32\n",
    "    data = minmax_scale(data,(-1.,1.))\n",
    "    fft_image = np.abs(fft.rfft(data,norm='forward'))\n",
    "    fft_freq = fft.rfftfreq(len(data),1./rate)\n",
    "    note_volumes = []\n",
    "    for note in NOTES:        \n",
    "    \n",
    "        note_volumes.append(get_note_volume(note,fft_image,fft_freq))\n",
    "    # print(note_volumes)\n",
    "    \n",
    "    return note_volumes\n",
    "\n",
    "# create a new dataframe with the note volumes\n",
    "train_note_volumes = pd.DataFrame(columns=NOTES)\n",
    "test_note_volumes = pd.DataFrame(columns=NOTES)    \n",
    "\n",
    "for i in tqdm(range(len(train_set))):\n",
    "    fileName = train_set['File Path'].iloc[i]\n",
    "    note_volumes = preprocess(fileName)\n",
    "    # print the shape of note_volumes\n",
    "    # print(note_volumes.shape)\n",
    "    for j in range(len(note_volumes)):\n",
    "        train_note_volumes.at[i, NOTES[j]] = note_volumes[j]\n",
    "\n",
    "for i in tqdm(range(len(test_set))):\n",
    "    fileName = test_set['File Path'].iloc[i]\n",
    "    note_volumes = preprocess(fileName)\n",
    "    for j in range(len(note_volumes)):\n",
    "        test_note_volumes.at[i, NOTES[j]] = note_volumes[j]\n",
    "        # test_set.iloc[i][NOTES[j]] = note_volumes[j]\n",
    "        # test_set.at[i, NOTES[j]] = note_volumes[j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "713"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# summarise the quality column in train_set\n",
    "train_set['Quality'].describe()\n",
    "\n",
    "# show each quality in train_set and how many there are\n",
    "train_set.groupby(['Quality']).count()\n",
    "\n",
    "\n",
    "# how many nan values are there in the train_set?\n",
    "\n",
    "# add the qualities to the note_volumes dataframe\n",
    "train_note_volumes['Quality'] = train_set['Quality']\n",
    "test_note_volumes['Quality'] = test_set['Quality']\n",
    "\n",
    "len(train_note_volumes)\n",
    "\n",
    "\n",
    "# print(train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>A#</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>C#</th>\n",
       "      <th>D</th>\n",
       "      <th>D#</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>F#</th>\n",
       "      <th>G</th>\n",
       "      <th>G#</th>\n",
       "      <th>Quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>dim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.007999</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.005141</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>maj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>0.00356</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.002209</td>\n",
       "      <td>0.002292</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.002329</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>aug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.008392</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.005519</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>aug</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A        A#         B         C        C#         D        D#  \\\n",
       "0   0.00003  0.000025  0.000018  0.000055  0.000036  0.000027  0.000013   \n",
       "1  0.000044  0.000055  0.000015  0.000029  0.000035  0.000057  0.000049   \n",
       "2  0.000499  0.000167  0.000135  0.007999  0.000137   0.00011  0.005141   \n",
       "3  0.000124  0.000125  0.002133   0.00356  0.000071  0.000068  0.002209   \n",
       "4  0.000223  0.000155  0.008392  0.000298  0.000249  0.000301    0.0052   \n",
       "\n",
       "          E         F        F#         G        G# Quality  \n",
       "0  0.000015  0.000025  0.000013  0.000023  0.000039     dim  \n",
       "1  0.000026  0.000057  0.000043  0.000023  0.000062     min  \n",
       "2  0.000042   0.00003  0.000057    0.0023  0.002004     maj  \n",
       "3  0.002292  0.000042  0.000077  0.002329  0.002155     aug  \n",
       "4  0.000319  0.000039  0.000159  0.005519  0.000599     aug  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_note_volumes['Quality'].isnull().sum()\n",
    "train_note_volumes['Quality'].describe()\n",
    "train_note_volumes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               File Path Root Note  Octave Quality  Inversion  \\\n",
      "0   data/chords/dim/Eb-7-dim-chord-1.wav        Eb       7     dim          1   \n",
      "3   data/chords/min/Bb-5-min-chord-0.wav        Bb       5     min          0   \n",
      "20  data/chords/maj/Ab-3-maj-chord-1.wav        Ab       3     maj          1   \n",
      "28  data/chords/aug/Ab-2-aug-chord-0.wav        Ab       2     aug          0   \n",
      "32   data/chords/aug/G-4-aug-chord-1.wav         G       4     aug          1   \n",
      "\n",
      "           A        A#         B         C        C#         D        D#  \\\n",
      "0   0.000693  0.030367  0.000416  0.000121  0.009097  0.000226  0.000272   \n",
      "3   0.000693  0.030367  0.000416  0.000121  0.009097  0.000226  0.000272   \n",
      "20  0.000693  0.030367  0.000416  0.000121  0.009097  0.000226  0.000272   \n",
      "28  0.000693  0.030367  0.000416  0.000121  0.009097  0.000226  0.000272   \n",
      "32  0.000693  0.030367  0.000416  0.000121  0.009097  0.000226  0.000272   \n",
      "\n",
      "           E         F        F#         G        G#  \n",
      "0   0.000194  0.004041  0.000067  0.000041  0.000066  \n",
      "3   0.000194  0.004041  0.000067  0.000041  0.000066  \n",
      "20  0.000194  0.004041  0.000067  0.000041  0.000066  \n",
      "28  0.000194  0.004041  0.000067  0.000041  0.000066  \n",
      "32  0.000194  0.004041  0.000067  0.000041  0.000066  \n",
      "                               File Path Root Note  Octave Quality  Inversion  \\\n",
      "0   data/chords/dim/Eb-7-dim-chord-1.wav        Eb       7     dim          1   \n",
      "3   data/chords/min/Bb-5-min-chord-0.wav        Bb       5     min          0   \n",
      "20  data/chords/maj/Ab-3-maj-chord-1.wav        Ab       3     maj          1   \n",
      "28  data/chords/aug/Ab-2-aug-chord-0.wav        Ab       2     aug          0   \n",
      "32   data/chords/aug/G-4-aug-chord-1.wav         G       4     aug          1   \n",
      "\n",
      "      A   A#    B    C   C#    D   D#    E    F   F#    G   G#  \n",
      "0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "20  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "28  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "32  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Assuming df is your DataFrame and it's already been normalized row-wise\n",
    "\n",
    "# Create a scaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the data but not for the 'File Path', Inversion, Root Note, Quality, and Chord Name columns\n",
    "\n",
    "columns_to_scale = train_set.drop(columns=['File Path', 'Quality', 'Root Note', 'Octave', 'Inversion']).columns\n",
    "train_set[columns_to_scale] = scaler.fit_transform(train_set[columns_to_scale])\n",
    "\n",
    "print(train_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dim' 'min' 'maj' 'aug']\n",
      "713\n"
     ]
    }
   ],
   "source": [
    "print(train_note_volumes['Quality'].unique())\n",
    "print(len(train_set))\n",
    "# remove the chords that have nan values in train_set\n",
    "train_set = train_set.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adrianmcintosh/Library/Python/3.9/lib/python/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "# run a CNN on the data, using the note volumes as the input and the chord quality as the output\n",
    "# Path: stage_3_cnn_classifier_part_2.ipynb\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "\n",
    "num_classes = 4\n",
    "height = 12\n",
    "width = 1\n",
    "channels = 1\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Add Convolutional layers\n",
    "model.add(Conv1D(32, 3, activation='relu', input_shape=(height, channels)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Conv1D(32, 3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# Flatten the output to feed into dense layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add Dense layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/adrianmcintosh/Desktop/UCLA/EC ENGR M146/Project/stage_3_cnn_classifier_part_1.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X36sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X36sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Assuming you have already loaded train_note_volumes and labels from your data\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X36sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Make sure to convert labels to categorical\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X36sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X36sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Convert labels to categorical one-hot encoding\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X36sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m labels_categorical \u001b[39m=\u001b[39m to_categorical(train_note_volumes[\u001b[39m'\u001b[39;49m\u001b[39mQuality\u001b[39;49m\u001b[39m'\u001b[39;49m], num_classes\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X36sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# make input_data a combination of train_note_volumes and test_note_volumes\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X36sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m input_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((train_note_volumes\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mQuality\u001b[39m\u001b[39m'\u001b[39m]), test_note_volumes\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mQuality\u001b[39m\u001b[39m'\u001b[39m])), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/utils/numerical_utils.py:92\u001b[0m, in \u001b[0;36mto_categorical\u001b[0;34m(x, num_classes)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39mif\u001b[39;00m backend\u001b[39m.\u001b[39mis_tensor(x):\n\u001b[1;32m     91\u001b[0m     \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mone_hot(x, num_classes)\n\u001b[0;32m---> 92\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray(x, dtype\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mint64\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     93\u001b[0m input_shape \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\n\u001b[1;32m     95\u001b[0m \u001b[39m# Shrink the last dimension if the shape is (..., 1).\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/series.py:953\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    907\u001b[0m \u001b[39mReturn the values as a NumPy array.\u001b[39;00m\n\u001b[1;32m    908\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[39m      dtype='datetime64[ns]')\u001b[39;00m\n\u001b[1;32m    951\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    952\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values\n\u001b[0;32m--> 953\u001b[0m arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(values, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    954\u001b[0m \u001b[39mif\u001b[39;00m using_copy_on_write() \u001b[39mand\u001b[39;00m astype_is_view(values\u001b[39m.\u001b[39mdtype, arr\u001b[39m.\u001b[39mdtype):\n\u001b[1;32m    955\u001b[0m     arr \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mview()\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'dim'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming you have already loaded train_note_volumes and labels from your data\n",
    "# Make sure to convert labels to categorical\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "labels_categorical = to_categorical(train_note_volumes['Quality'], num_classes=4)\n",
    "\n",
    "# make input_data a combination of train_note_volumes and test_note_volumes\n",
    "\n",
    "input_data = np.concatenate((train_note_volumes.drop(columns=['Quality']), test_note_volumes.drop(columns=['Quality'])), axis=0)\n",
    "\n",
    "# Reshape input data to have a channel dimension\n",
    "input_data = input_data.reshape(input_data.shape[0], input_data.shape[1], 1)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(input_data, labels_categorical, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build a simple CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(input_data.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))  # For multi-class classification with 4 classes\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(input_data, labels_categorical)\n",
    "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aug' 'dim' 'maj' 'min']\n",
      "[1 3 2 0 0 3 2 1 3 1 3 2 3 0 0 0 3 3 1 1 2 1 2 1 2 2 2 0 1 2 2 0 0 0 1 0 0\n",
      " 1 1 0 2 0 0 1 2 3 0 3 1 0 0 1 1 1 2 1 2 0 3 3 3 0 2 1 1 1 2 0 2 2 1 2 0 0\n",
      " 3 1 2 2 0 2 0 1 3 3 3 3 3 2 1 1 2 3 3 0 3 3 3 1 3 3 2 2 0 0 1 2 0 2 1 1 1\n",
      " 2 2 2 3 3 3 3 2 3 0 1 1 0 3 2 1 3 0 2 3 0 2 2 0 0 0 0 3 1 2 2 1 1 2 2 1 2\n",
      " 2 3 0 3 0 0 1 0 1 2 3 1 3 2 3 1 2 3 2 2 2 0 2 3 3 3 1 1 3 3 3 1 0 0 1 0 3\n",
      " 1 3 0 0 3 1 1 0 0 1 1 0 0 0 2 0 0 2 3 1 3 3 3 3 0 2 1 3 3 3 1 2 0 3 0 3 1\n",
      " 0 0 0 1 0 0 1 1 0 3 1 1 1 0 0 0 3 1 3 1 3 2 2 2 2 3 3 2 0 1 2 3 0 1 1 2 3\n",
      " 0 0 1 2 2 1 3 3 0 3 2 3 2 1 1 0 1 1 2 0 3 0 3 2 0 0 0 0 1 0 2 2 2 1 2 3 1\n",
      " 2 3 0 1 3 0 1 3 2 1 0 0 3 3 2 3 2 0 2 1 3 3 2 1 1 2 0 2 1 1 0 0 3 2 3 0 0\n",
      " 3 0 1 0 3 2 2 2 1 0 0 0 3 2 0 3 0 3 0 3 3 0 0 3 1 2 3 2 0 2 1 2 0 1 0 0 3\n",
      " 0 2 2 1 0 1 0 1 0 1 2 1 1 2 0 1 0 3 2 2 2 1 0 2 3 2 1 0 0 0 0 1 3 2 0 2 3\n",
      " 3 3 2 1 2 2 3 1 1 1 0 2 3 1 0 2 1 3 2 3 1 3 2 1 1 3 3 1 2 2 3 0 0 3 3 3 2\n",
      " 3 0 3 0 3 0 0 3 1 2 3 3 3 0 1 0 3 3 1 1 2 1 2 0 3 0 1 3 3 3 2 1 3 0 1 0 0\n",
      " 2 1 3 0 2 3 0 2 3 3 0 2 1 1 1 3 2 2 3 2 1 1 1 1 2 1 2 2 1 0 1 0 3 2 1 1 2\n",
      " 1 2 3 3 0 3 2 1 3 0 1 2 2 0 2 1 3 0 0 1 3 0 1 3 3 0 2 1 1 1 2 3 1 2 0 2 1\n",
      " 1 1 0 0 0 1 3 1 0 2 0 2 2 3 0 1 0 1 1 0 0 2 3 0 1 3 2 2 3 0 1 2 3 0 3 0 2\n",
      " 2 2 2 2 2 1 3 1 3 3 1 1 0 2 0 2 0 2 2 3 2 3 1 2 0 1 3 3 0 2 1 0 3 0 1 2 0\n",
      " 3 0 1 2 3 3 2 2 3 2 3 1 2 1 1 3 1 3 2 2 0 1 2 2 2 2 0 0 3 0 0 1 3 0 1 0 1\n",
      " 0 1 2 3 3 0 2 3 2 1 1 1 3 2 0 2 3 3 1 3 0 3 3 0 2 2 2 3 0 2 1 1 0 3 1 1 3\n",
      " 2 2 1 1 2 1 0 1 2 3]\n",
      "[0 0 3 0 1 2 1 2 0 3 0 2 3 1 0 1 2 2 0 3 2 3 3 3 3 1 2 3 1 1 3 2 0 0 3 1 1\n",
      " 2 2 2 1 3 0 2 2 0 0 1 0 0 2 1 3 0 3 3 3 3 2 3 0 1 3 2 0 2 1 0 1 1 1 2 0 1\n",
      " 2 3 0 2 3 3 2 0 2 0 0 3 1 3 2 3 1 1 2 2 0 1 1 1 1 2 3 0 0 0 0 0 1 2 0 2 0\n",
      " 1 2 2 1 0 3 0 2 1 0 0 1 3 1 3 0 2 0 0 1 3 1 1 0 1 0 1 3 2 0 3 2 1 0 3 0 3\n",
      " 1 3 3 1 2 1 1 2 1 3 0 1 2 2 3 1 2 1 2 3 2 3 1 0 3 3 1 0 1 3 0 3 0 2 2 1 0\n",
      " 1 3 1 1 3 3 3 0 1 2 2 2 3 0 0 2 0 2 2 0 1 1 3 1 1 2 1 3 2 0 1 0 3 0 2 1 1\n",
      " 3 0 3 1 3 3 1 1 0 2 0 0 2 2 3 1 1 2 2 1 0 3 0 1 1 1 2 0 3 2 3 2 0 1 3 3 2\n",
      " 3 1 3 3 1 3 3 3 2 3 2 2 1 0 2 2 3 3 0 2 2 2 3 3 2 2 3 0 3 3 2 2 0 0 0 2 1\n",
      " 2 0 0 0 2 2 3 0 1 1 0]\n",
      "4\n",
      "4\n",
      "[0. 1. 0. 0.]\n",
      "[1. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adrianmcintosh/Library/Python/3.9/lib/python/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/adrianmcintosh/Desktop/UCLA/EC ENGR M146/Project/stage_3_cnn_classifier_part_1.ipynb Cell 19\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X22sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mprint\u001b[39m(test_set_one_hot[\u001b[39m0\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X22sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# fit the model using train_set_note_volumes and train_set_one_hot, but exclude the File Path, Quality, and Root Note columns\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X22sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_note_volumes\u001b[39m.\u001b[39;49mdrop(columns\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mQuality\u001b[39;49m\u001b[39m'\u001b[39;49m]), train_set_one_hot, epochs\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X22sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# evaluate on test_set\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X22sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m model\u001b[39m.\u001b[39mevaluate(test_note_volumes, test_set_one_hot)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m    121\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[39m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/framework/constant_op.py:103\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    102\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.float32)."
     ]
    }
   ],
   "source": [
    "\n",
    "# train_reshaped = train_set_note_volumes.reshape(train_set_note_volumes.shape[0], height, channels)\n",
    "# test_reshaped = test_set_note_volumes.reshape(train_set_note_volumes.shape[0], height, channels)\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "# Convert string inputs to numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_set_encoded = label_encoder.fit_transform(train_set[\"Quality\"])\n",
    "test_set_encoded = label_encoder.transform(test_set[\"Quality\"])\n",
    "\n",
    "# show the classes in train_set[\"Quality\"]\n",
    "print(label_encoder.classes_)\n",
    "\n",
    "# summarize the classes of train_set_encoded and test_set_encoded\n",
    "# count the number of classes in train_set_encoded and test_set_encoded\n",
    "print(train_set_encoded)\n",
    "print(test_set_encoded)\n",
    "\n",
    "print(len(np.unique(train_set_encoded)))\n",
    "print(len(np.unique(test_set_encoded)))\n",
    "\n",
    "# One-hot encode the numerical labels\n",
    "onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "train_set_one_hot = onehot_encoder.fit_transform(train_set_encoded.reshape(-1, 1))\n",
    "test_set_one_hot = onehot_encoder.transform(test_set_encoded.reshape(-1, 1))\n",
    "\n",
    "# Check the number of classes in train_set_one_hot and test_set_one_hot\n",
    "print(train_set_one_hot[0])\n",
    "print(test_set_one_hot[0])\n",
    "\n",
    "# fit the model using train_set_note_volumes and train_set_one_hot, but exclude the File Path, Quality, and Root Note columns\n",
    "model.fit(train_note_volumes.drop(columns=['Quality']), train_set_one_hot, epochs=3, batch_size=100)\n",
    "\n",
    "# evaluate on test_set\n",
    "model.evaluate(test_note_volumes, test_set_one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>A#</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>C#</th>\n",
       "      <th>D</th>\n",
       "      <th>D#</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>F#</th>\n",
       "      <th>G</th>\n",
       "      <th>G#</th>\n",
       "      <th>Quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>dim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.007999</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.005141</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>maj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>0.00356</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.002209</td>\n",
       "      <td>0.002292</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.002329</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>aug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.008392</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.005519</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>aug</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A        A#         B         C        C#         D        D#  \\\n",
       "0   0.00003  0.000025  0.000018  0.000055  0.000036  0.000027  0.000013   \n",
       "1  0.000044  0.000055  0.000015  0.000029  0.000035  0.000057  0.000049   \n",
       "2  0.000499  0.000167  0.000135  0.007999  0.000137   0.00011  0.005141   \n",
       "3  0.000124  0.000125  0.002133   0.00356  0.000071  0.000068  0.002209   \n",
       "4  0.000223  0.000155  0.008392  0.000298  0.000249  0.000301    0.0052   \n",
       "\n",
       "          E         F        F#         G        G# Quality  \n",
       "0  0.000015  0.000025  0.000013  0.000023  0.000039     dim  \n",
       "1  0.000026  0.000057  0.000043  0.000023  0.000062     min  \n",
       "2  0.000042   0.00003  0.000057    0.0023  0.002004     maj  \n",
       "3  0.002292  0.000042  0.000077  0.002329  0.002155     aug  \n",
       "4  0.000319  0.000039  0.000159  0.005519  0.000599     aug  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalise the data so that the volum\n",
    "train_set_one_hot\n",
    "len(train_set_one_hot)\n",
    "train_note_volumes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.18566775244299674"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try running random forrests on the data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=0)\n",
    "rf.fit(train_note_volumes.drop(columns=['Quality']), train_set_one_hot)\n",
    "preds = rf.predict(test_note_volumes.drop(columns=['Quality']))\n",
    "print(preds)\n",
    "accuracy_score(test_set_one_hot, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adrianmcintosh/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/dense.py:73: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/adrianmcintosh/Library/Python/3.9/lib/python/site-packages/keras/src/optimizers/base_optimizer.py:31: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.2162 - loss: 1.3865\n",
      "Epoch 2/3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.2269 - loss: 1.3861\n",
      "Epoch 3/3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2608 - loss: 1.3866 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x28c677640>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try running a neural network on the data\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=12))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_set.drop(columns=['File Path', 'Quality', 'Root Note', 'Octave', 'Inversion']), train_set_one_hot, epochs=3, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try running knn on the data\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(train_note_volumes.drop(columns=['Quality']), train_note_volumes['Quality'])\n",
    "preds = knn.predict(test_note_volumes.drop(columns=['Quality']))\n",
    "accuracy_score(test_set['Quality'], preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, The experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:A: object, A#: object, B: object, C: object, C#: object, D: object, D#: object, E: object, F: object, F#: object, G: object, G#: object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/adrianmcintosh/Desktop/UCLA/EC ENGR M146/Project/stage_3_cnn_classifier_part_1.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m xgb \u001b[39m=\u001b[39m XGBClassifier()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m xgb\u001b[39m.\u001b[39;49mfit(train_note_volumes\u001b[39m.\u001b[39;49mdrop(columns\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mQuality\u001b[39;49m\u001b[39m'\u001b[39;49m]), train_set[\u001b[39m'\u001b[39;49m\u001b[39mQuality\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m preds \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mpredict(test_note_volumes\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mQuality\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m accuracy_score(test_set[\u001b[39m'\u001b[39m\u001b[39mQuality\u001b[39m\u001b[39m'\u001b[39m], preds)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/sklearn.py:1496\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1485\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mnum_class\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_\n\u001b[1;32m   1487\u001b[0m (\n\u001b[1;32m   1488\u001b[0m     model,\n\u001b[1;32m   1489\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1494\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1495\u001b[0m )\n\u001b[0;32m-> 1496\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1497\u001b[0m     missing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmissing,\n\u001b[1;32m   1498\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m   1499\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m   1500\u001b[0m     group\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1501\u001b[0m     qid\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1502\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1503\u001b[0m     base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[1;32m   1504\u001b[0m     feature_weights\u001b[39m=\u001b[39;49mfeature_weights,\n\u001b[1;32m   1505\u001b[0m     eval_set\u001b[39m=\u001b[39;49meval_set,\n\u001b[1;32m   1506\u001b[0m     sample_weight_eval_set\u001b[39m=\u001b[39;49msample_weight_eval_set,\n\u001b[1;32m   1507\u001b[0m     base_margin_eval_set\u001b[39m=\u001b[39;49mbase_margin_eval_set,\n\u001b[1;32m   1508\u001b[0m     eval_group\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1509\u001b[0m     eval_qid\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1510\u001b[0m     create_dmatrix\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_dmatrix,\n\u001b[1;32m   1511\u001b[0m     enable_categorical\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menable_categorical,\n\u001b[1;32m   1512\u001b[0m     feature_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_types,\n\u001b[1;32m   1513\u001b[0m )\n\u001b[1;32m   1515\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1516\u001b[0m     params,\n\u001b[1;32m   1517\u001b[0m     train_dmatrix,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1526\u001b[0m     callbacks\u001b[39m=\u001b[39mcallbacks,\n\u001b[1;32m   1527\u001b[0m )\n\u001b[1;32m   1529\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/sklearn.py:534\u001b[0m, in \u001b[0;36m_wrap_evaluation_matrices\u001b[0;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrap_evaluation_matrices\u001b[39m(\n\u001b[1;32m    515\u001b[0m     missing: \u001b[39mfloat\u001b[39m,\n\u001b[1;32m    516\u001b[0m     X: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    530\u001b[0m     feature_types: Optional[FeatureTypes],\n\u001b[1;32m    531\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Any, List[Tuple[Any, \u001b[39mstr\u001b[39m]]]:\n\u001b[1;32m    532\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Convert array_like evaluation matrices into DMatrix.  Perform validation on the\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[39m    way.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 534\u001b[0m     train_dmatrix \u001b[39m=\u001b[39m create_dmatrix(\n\u001b[1;32m    535\u001b[0m         data\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    536\u001b[0m         label\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    537\u001b[0m         group\u001b[39m=\u001b[39;49mgroup,\n\u001b[1;32m    538\u001b[0m         qid\u001b[39m=\u001b[39;49mqid,\n\u001b[1;32m    539\u001b[0m         weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    540\u001b[0m         base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[1;32m    541\u001b[0m         feature_weights\u001b[39m=\u001b[39;49mfeature_weights,\n\u001b[1;32m    542\u001b[0m         missing\u001b[39m=\u001b[39;49mmissing,\n\u001b[1;32m    543\u001b[0m         enable_categorical\u001b[39m=\u001b[39;49menable_categorical,\n\u001b[1;32m    544\u001b[0m         feature_types\u001b[39m=\u001b[39;49mfeature_types,\n\u001b[1;32m    545\u001b[0m         ref\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    546\u001b[0m     )\n\u001b[1;32m    548\u001b[0m     n_validation \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m eval_set \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mlen\u001b[39m(eval_set)\n\u001b[1;32m    550\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mvalidate_or_none\u001b[39m(meta: Optional[Sequence], name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Sequence:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/sklearn.py:954\u001b[0m, in \u001b[0;36mXGBModel._create_dmatrix\u001b[0;34m(self, ref, **kwargs)\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[39mif\u001b[39;00m _can_use_qdm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_method) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbooster \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgblinear\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    953\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 954\u001b[0m         \u001b[39mreturn\u001b[39;00m QuantileDMatrix(\n\u001b[1;32m    955\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs, ref\u001b[39m=\u001b[39;49mref, nthread\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs, max_bin\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_bin\n\u001b[1;32m    956\u001b[0m         )\n\u001b[1;32m    957\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:  \u001b[39m# `QuantileDMatrix` supports lesser types than DMatrix\u001b[39;00m\n\u001b[1;32m    958\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:1528\u001b[0m, in \u001b[0;36mQuantileDMatrix.__init__\u001b[0;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, max_bin, ref, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical, data_split_mode)\u001b[0m\n\u001b[1;32m   1508\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(\n\u001b[1;32m   1509\u001b[0m         info \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m         \u001b[39mfor\u001b[39;00m info \u001b[39min\u001b[39;00m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1521\u001b[0m         )\n\u001b[1;32m   1522\u001b[0m     ):\n\u001b[1;32m   1523\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1524\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mIf data iterator is used as input, data like label should be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1525\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mspecified as batch argument.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1526\u001b[0m         )\n\u001b[0;32m-> 1528\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init(\n\u001b[1;32m   1529\u001b[0m     data,\n\u001b[1;32m   1530\u001b[0m     ref\u001b[39m=\u001b[39;49mref,\n\u001b[1;32m   1531\u001b[0m     label\u001b[39m=\u001b[39;49mlabel,\n\u001b[1;32m   1532\u001b[0m     weight\u001b[39m=\u001b[39;49mweight,\n\u001b[1;32m   1533\u001b[0m     base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[1;32m   1534\u001b[0m     group\u001b[39m=\u001b[39;49mgroup,\n\u001b[1;32m   1535\u001b[0m     qid\u001b[39m=\u001b[39;49mqid,\n\u001b[1;32m   1536\u001b[0m     label_lower_bound\u001b[39m=\u001b[39;49mlabel_lower_bound,\n\u001b[1;32m   1537\u001b[0m     label_upper_bound\u001b[39m=\u001b[39;49mlabel_upper_bound,\n\u001b[1;32m   1538\u001b[0m     feature_weights\u001b[39m=\u001b[39;49mfeature_weights,\n\u001b[1;32m   1539\u001b[0m     feature_names\u001b[39m=\u001b[39;49mfeature_names,\n\u001b[1;32m   1540\u001b[0m     feature_types\u001b[39m=\u001b[39;49mfeature_types,\n\u001b[1;32m   1541\u001b[0m     enable_categorical\u001b[39m=\u001b[39;49menable_categorical,\n\u001b[1;32m   1542\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:1587\u001b[0m, in \u001b[0;36mQuantileDMatrix._init\u001b[0;34m(self, data, ref, enable_categorical, **meta)\u001b[0m\n\u001b[1;32m   1575\u001b[0m config \u001b[39m=\u001b[39m make_jcargs(\n\u001b[1;32m   1576\u001b[0m     nthread\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnthread, missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing, max_bin\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_bin\n\u001b[1;32m   1577\u001b[0m )\n\u001b[1;32m   1578\u001b[0m ret \u001b[39m=\u001b[39m _LIB\u001b[39m.\u001b[39mXGQuantileDMatrixCreateFromCallback(\n\u001b[1;32m   1579\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1580\u001b[0m     it\u001b[39m.\u001b[39mproxy\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1585\u001b[0m     ctypes\u001b[39m.\u001b[39mbyref(handle),\n\u001b[1;32m   1586\u001b[0m )\n\u001b[0;32m-> 1587\u001b[0m it\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m   1588\u001b[0m \u001b[39m# delay check_call to throw intermediate exception first\u001b[39;00m\n\u001b[1;32m   1589\u001b[0m _check_call(ret)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:575\u001b[0m, in \u001b[0;36mDataIter.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    573\u001b[0m exc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    574\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:556\u001b[0m, in \u001b[0;36mDataIter._handle_exception\u001b[0;34m(self, fn, dft_ret)\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[39mreturn\u001b[39;00m dft_ret\n\u001b[1;32m    555\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 556\u001b[0m     \u001b[39mreturn\u001b[39;00m fn()\n\u001b[1;32m    557\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    558\u001b[0m     \u001b[39m# Defer the exception in order to return 0 and stop the iteration.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m     \u001b[39m# Exception inside a ctype callback function has no effect except\u001b[39;00m\n\u001b[1;32m    560\u001b[0m     \u001b[39m# for printing to stderr (doesn't stop the execution).\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     tb \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()[\u001b[39m2\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:640\u001b[0m, in \u001b[0;36mDataIter._next_wrapper.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_ref \u001b[39m=\u001b[39m ref\n\u001b[1;32m    639\u001b[0m \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m--> 640\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_exception(\u001b[39mlambda\u001b[39;00m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext(input_data), \u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/data.py:1280\u001b[0m, in \u001b[0;36mSingleBatchInternalIter.next\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m   1279\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mit \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1280\u001b[0m input_data(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n\u001b[1;32m   1281\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:623\u001b[0m, in \u001b[0;36mDataIter._next_wrapper.<locals>.input_data\u001b[0;34m(data, feature_names, feature_types, **kwargs)\u001b[0m\n\u001b[1;32m    621\u001b[0m     new, cat_codes, feature_names, feature_types \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_temporary_data\n\u001b[1;32m    622\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 623\u001b[0m     new, cat_codes, feature_names, feature_types \u001b[39m=\u001b[39m _proxy_transform(\n\u001b[1;32m    624\u001b[0m         data,\n\u001b[1;32m    625\u001b[0m         feature_names,\n\u001b[1;32m    626\u001b[0m         feature_types,\n\u001b[1;32m    627\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_enable_categorical,\n\u001b[1;32m    628\u001b[0m     )\n\u001b[1;32m    629\u001b[0m \u001b[39m# Stage the data, meta info are copied inside C++ MetaInfo.\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_temporary_data \u001b[39m=\u001b[39m (new, cat_codes, feature_names, feature_types)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/data.py:1315\u001b[0m, in \u001b[0;36m_proxy_transform\u001b[0;34m(data, feature_names, feature_types, enable_categorical)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data)\n\u001b[1;32m   1314\u001b[0m \u001b[39mif\u001b[39;00m _is_pandas_df(data):\n\u001b[0;32m-> 1315\u001b[0m     arr, feature_names, feature_types \u001b[39m=\u001b[39m _transform_pandas_df(\n\u001b[1;32m   1316\u001b[0m         data, enable_categorical, feature_names, feature_types\n\u001b[1;32m   1317\u001b[0m     )\n\u001b[1;32m   1318\u001b[0m     arr, _ \u001b[39m=\u001b[39m _ensure_np_dtype(arr, arr\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m   1319\u001b[0m     \u001b[39mreturn\u001b[39;00m arr, \u001b[39mNone\u001b[39;00m, feature_names, feature_types\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/data.py:490\u001b[0m, in \u001b[0;36m_transform_pandas_df\u001b[0;34m(data, enable_categorical, feature_names, feature_types, meta, meta_type)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[39mfor\u001b[39;00m dtype \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mdtypes:\n\u001b[1;32m    484\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\n\u001b[1;32m    485\u001b[0m         (dtype\u001b[39m.\u001b[39mname \u001b[39min\u001b[39;00m _pandas_dtype_mapper)\n\u001b[1;32m    486\u001b[0m         \u001b[39mor\u001b[39;00m is_pd_sparse_dtype(dtype)\n\u001b[1;32m    487\u001b[0m         \u001b[39mor\u001b[39;00m (is_pd_cat_dtype(dtype) \u001b[39mand\u001b[39;00m enable_categorical)\n\u001b[1;32m    488\u001b[0m         \u001b[39mor\u001b[39;00m is_pa_ext_dtype(dtype)\n\u001b[1;32m    489\u001b[0m     ):\n\u001b[0;32m--> 490\u001b[0m         _invalid_dataframe_dtype(data)\n\u001b[1;32m    491\u001b[0m     \u001b[39mif\u001b[39;00m is_pa_ext_dtype(dtype):\n\u001b[1;32m    492\u001b[0m         pyarrow_extension \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/data.py:308\u001b[0m, in \u001b[0;36m_invalid_dataframe_dtype\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    306\u001b[0m type_err \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDataFrame.dtypes for data must be int, float, bool or category.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\u001b[39m{\u001b[39;00mtype_err\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m_ENABLE_CAT_ERR\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00merr\u001b[39m}\u001b[39;00m\u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m--> 308\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, The experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:A: object, A#: object, B: object, C: object, C#: object, D: object, D#: object, E: object, F: object, F#: object, G: object, G#: object"
     ]
    }
   ],
   "source": [
    "# for every chord quality, set it to 0, 1, 2, 3\n",
    "train_set['Quality'] = train_set['Quality'].replace(['maj', 'min', 'dim', 'aug'], [0, 1, 2, 3])\n",
    "test_set['Quality'] = test_set['Quality'].replace(['maj', 'min', 'dim', 'aug'], [0, 1, 2, 3])\n",
    "\n",
    "# try running xgboost on the data\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(train_note_volumes.drop(columns=['Quality']), train_set['Quality'])\n",
    "preds = xgb.predict(test_note_volumes.drop(columns=['Quality']))\n",
    "accuracy_score(test_set['Quality'], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19543973941368079"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try running a naive bayes classifier on the data\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(train_set_note_volumes.drop(columns=['File Path', 'Quality', 'Root Note']), train_set['Quality'])\n",
    "preds = gnb.predict(test_set_note_volumes.drop(columns=['File Path', 'Quality', 'Root Note']))\n",
    "accuracy_score(test_set['Quality'], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model.evaluate(test_reshaped, test_set_one_hot)[1]\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50814332247557"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try running xgboost on the data\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(train_set_note_volumes.drop(columns=['File Path', 'Quality', 'Root Note']), train_set['Quality'])\n",
    "preds = xgb.predict(test_set_note_volumes.drop(columns=['File Path', 'Quality', 'Root Note']))\n",
    "accuracy_score(test_set['Quality'], preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/adrianmcintosh/Desktop/UCLA/EC ENGR M146/Project/stage_3_cnn_classifier_part_1.ipynb Cell 20\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X31sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m lr\u001b[39m.\u001b[39mfit(train_set_note_volumes\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mFile Path\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mQuality\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mRoot Note\u001b[39m\u001b[39m'\u001b[39m]), train_set[\u001b[39m'\u001b[39m\u001b[39mQuality\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X31sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m preds \u001b[39m=\u001b[39m lr\u001b[39m.\u001b[39mpredict(test_set_note_volumes\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mFile Path\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mQuality\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mRoot Note\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X31sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m accuracy_score(test_set[\u001b[39m'\u001b[39;49m\u001b[39mQuality\u001b[39;49m\u001b[39m'\u001b[39;49m], preds)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    215\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:220\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \n\u001b[1;32m    156\u001b[0m \u001b[39mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39m0.5\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[39m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 220\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    221\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    222\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m     92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     95\u001b[0m             type_true, type_pred\n\u001b[1;32m     96\u001b[0m         )\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     99\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    100\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "# try linear regression on the data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(train_set_note_volumes.drop(columns=['File Path', 'Quality', 'Root Note']), train_set['Quality'])\n",
    "preds = lr.predict(test_set_note_volumes.drop(columns=['File Path', 'Quality', 'Root Note']))\n",
    "accuracy_score(test_set['Quality'], preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               File Path Root Note  Octave  Quality  Inversion\n",
      "0   data/chords/dim/Eb-7-dim-chord-1.wav        Eb       7        2          1\n",
      "3   data/chords/min/Bb-5-min-chord-0.wav        Bb       5        1          0\n",
      "20  data/chords/maj/Ab-3-maj-chord-1.wav        Ab       3        0          1\n",
      "28  data/chords/aug/Ab-2-aug-chord-0.wav        Ab       2        3          0\n",
      "32   data/chords/aug/G-4-aug-chord-1.wav         G       4        3          1\n",
      "          0         1         2         3         4         5         6  \\\n",
      "0  0.000030  0.000025  0.000018  0.000055  0.000036  0.000027  0.000013   \n",
      "1  0.000044  0.000055  0.000015  0.000029  0.000035  0.000057  0.000049   \n",
      "2  0.000499  0.000167  0.000135  0.007999  0.000137  0.000110  0.005141   \n",
      "3  0.000124  0.000125  0.002133  0.003560  0.000071  0.000068  0.002209   \n",
      "4  0.000223  0.000155  0.008392  0.000298  0.000249  0.000301  0.005200   \n",
      "\n",
      "          7         8         9        10        11  \\\n",
      "0  0.000015  0.000025  0.000013  0.000023  0.000039   \n",
      "1  0.000026  0.000057  0.000043  0.000023  0.000062   \n",
      "2  0.000042  0.000030  0.000057  0.002300  0.002004   \n",
      "3  0.002292  0.000042  0.000077  0.002329  0.002155   \n",
      "4  0.000319  0.000039  0.000159  0.005519  0.000599   \n",
      "\n",
      "                              File Path Quality Root Note  \n",
      "0  data/chords/dim/Eb-7-dim-chord-1.wav     dim        Eb  \n",
      "1                                   NaN     NaN       NaN  \n",
      "2                                   NaN     NaN       NaN  \n",
      "3  data/chords/min/Bb-5-min-chord-0.wav     min        Bb  \n",
      "4                                   NaN     NaN       NaN  \n",
      "                0           1           2           3           4           5  \\\n",
      "count  713.000000  713.000000  713.000000  713.000000  713.000000  713.000000   \n",
      "mean     0.001453    0.001869    0.001236    0.001039    0.001180    0.001139   \n",
      "std      0.004012    0.005431    0.002517    0.002013    0.002435    0.002095   \n",
      "min      0.000003    0.000005    0.000004    0.000006    0.000005    0.000003   \n",
      "25%      0.000048    0.000042    0.000040    0.000040    0.000034    0.000036   \n",
      "50%      0.000111    0.000107    0.000094    0.000107    0.000097    0.000095   \n",
      "75%      0.000560    0.000583    0.000645    0.000450    0.000639    0.000929   \n",
      "max      0.024434    0.032115    0.012638    0.009314    0.011039    0.009749   \n",
      "\n",
      "                6           7           8           9          10          11  \n",
      "count  713.000000  713.000000  713.000000  713.000000  713.000000  713.000000  \n",
      "mean     0.000948    0.000932    0.000782    0.000812    0.000686    0.000786  \n",
      "std      0.001653    0.001598    0.001352    0.001302    0.001172    0.001314  \n",
      "min      0.000006    0.000006    0.000007    0.000003    0.000003    0.000005  \n",
      "25%      0.000035    0.000033    0.000030    0.000031    0.000029    0.000030  \n",
      "50%      0.000088    0.000070    0.000061    0.000057    0.000058    0.000058  \n",
      "75%      0.000864    0.000971    0.001041    0.001377    0.001245    0.001447  \n",
      "max      0.007171    0.007057    0.006080    0.005639    0.006271    0.007292  \n"
     ]
    }
   ],
   "source": [
    "# print a summary of train_set\n",
    "print(train_set.head())\n",
    "print(train_set_note_volumes.head())\n",
    "\n",
    "# summarise note volumes\n",
    "print(train_set_note_volumes.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "import scipy.signal as signal\n",
    "\n",
    "def load_wav_16k_mono(filename):\n",
    "    sample_rate, wav_data = wav.read(filename)\n",
    "    if wav_data.ndim > 1:\n",
    "        wav_data = wav_data[:, 0]\n",
    "    return wav_data, sample_rate\n",
    "\n",
    "# def preprocess(file_path, label):\n",
    "#     wav_data, sample_rate = load_wav_16k_mono(file_path)\n",
    "#     wav_data = wav_data[:48000]\n",
    "#     zero_padding = np.zeros(48000 - len(wav_data), dtype=np.float32)\n",
    "#     wav_data = np.concatenate([zero_padding, wav_data])\n",
    "#     spectrogram = np.abs(signal.stft(wav_data, nperseg=320, noverlap=288)[2])\n",
    "#     spectrogram = np.expand_dims(spectrogram, axis=2)\n",
    "#     return spectrogram, label\n",
    "\n",
    "def preprocess(file_path, label):\n",
    "    wav_data, sample_rate = load_wav_16k_mono(file_path)\n",
    "    wav_data = wav_data[:48000]\n",
    "    zero_padding = np.zeros(48000 - len(wav_data), dtype=np.float32)\n",
    "    wav_data = np.concatenate([zero_padding, wav_data])\n",
    "    spectrogram = np.abs(signal.stft(wav_data, nperseg=320, noverlap=288)[2])\n",
    "    \n",
    "    # Add an extra dimension to the spectrogram before resizing\n",
    "    spectrogram = tf.expand_dims(spectrogram, axis=-1)\n",
    "    \n",
    "    # Ensure the spectrogram has the correct dimensions\n",
    "    spectrogram = tf.image.resize(spectrogram, [1501, 161])\n",
    "\n",
    "    return spectrogram, label\n",
    "\n",
    "# def preprocess(file_path, label):\n",
    "#     wav = load_wav_16k_mono(file_path)\n",
    "#     wav = wav[:48000]\n",
    "#     zero_padding = tf.zeros([48000] - tf.shape(wav), dtype=tf.float32)\n",
    "#     wav = tf.concat([zero_padding, wav],0)\n",
    "#     spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
    "#     spectrogram = tf.abs(spectrogram)\n",
    "#     spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
    "#     return spectrogram, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram, label = preprocess(train_set['File Path'].iloc[0], train_set['Quality'].iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3000x2000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(30,20))\n",
    "plt.imshow(spectrogram)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161, 1501, 1)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the dimensions of spectrogram\n",
    "spectrogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Path</th>\n",
       "      <th>Quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/chords/dim/Eb-7-dim-chord-1.wav</td>\n",
       "      <td>dim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/chords/min/Bb-5-min-chord-0.wav</td>\n",
       "      <td>min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>data/chords/maj/Ab-3-maj-chord-1.wav</td>\n",
       "      <td>maj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>data/chords/aug/Ab-2-aug-chord-0.wav</td>\n",
       "      <td>aug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>data/chords/aug/G-4-aug-chord-1.wav</td>\n",
       "      <td>aug</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               File Path Quality\n",
       "0   data/chords/dim/Eb-7-dim-chord-1.wav     dim\n",
       "3   data/chords/min/Bb-5-min-chord-0.wav     min\n",
       "20  data/chords/maj/Ab-3-maj-chord-1.wav     maj\n",
       "28  data/chords/aug/Ab-2-aug-chord-0.wav     aug\n",
       "32   data/chords/aug/G-4-aug-chord-1.wav     aug"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a tf.data.Dataset from your DataFrame\n",
    "file_paths = tf.data.Dataset.from_tensor_slices(train_set['File Path'])\n",
    "qualities = tf.data.Dataset.from_tensor_slices(train_set['Quality'])\n",
    "data = tf.data.Dataset.zip((file_paths, qualities))\n",
    "\n",
    "# Apply the preprocess function\n",
    "def tf_preprocess(file_path, quality):\n",
    "    [file_path, quality] = tf.py_function(preprocess, [file_path, quality], [tf.string, tf.string])\n",
    "    file_path.set_shape(())\n",
    "    quality.set_shape(())\n",
    "    return file_path, quality\n",
    "\n",
    "data = data.map(tf_preprocess)\n",
    "# Apply the other methods\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=1000)\n",
    "data = data.batch(16)\n",
    "data = data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.take(37)\n",
    "test = data.skip(37).take(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(1501, 161, 1)))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(4, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('Adam', loss='CategoricalCrossentropy', metrics=[tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_19\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_19\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">    Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1499</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">159</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1497</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">157</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,320</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ flatten_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3760464</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15,041,860</span> │\n",
       "└─────────────────────────────────┴───────────────────────────┴────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1499\u001b[0m, \u001b[38;5;34m159\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │        \u001b[38;5;34m160\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1497\u001b[0m, \u001b[38;5;34m157\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │      \u001b[38;5;34m2,320\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ flatten_11 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3760464\u001b[0m)           │          \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                 │ \u001b[38;5;34m15,041,860\u001b[0m │\n",
       "└─────────────────────────────────┴───────────────────────────┴────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,044,340</span> (57.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,044,340\u001b[0m (57.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,044,340</span> (57.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,044,340\u001b[0m (57.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming test_set is a DataFrame with 'File Path' and 'Quality' columns\n",
    "\n",
    "# Create a tf.data.Dataset from your test_set DataFrame\n",
    "test_file_paths = tf.data.Dataset.from_tensor_slices(test_set['File Path'])\n",
    "test_qualities = tf.data.Dataset.from_tensor_slices(test_set['Quality'])\n",
    "test_data = tf.data.Dataset.zip((test_file_paths, test_qualities))\n",
    "\n",
    "# Apply the preprocess function\n",
    "test_data = test_data.map(tf_preprocess)\n",
    "\n",
    "# Apply the other methods\n",
    "test_data = test_data.cache()\n",
    "test_data = test_data.shuffle(buffer_size=1000)\n",
    "test_data = test_data.batch(16)\n",
    "test_data = test_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"sequential_19_1/Cast:0\", shape=(None,), dtype=float32). Expected shape (None, 1501, 161, 1), but input has incompatible shape (None,)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None,), dtype=string)\n  • training=True\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/adrianmcintosh/Desktop/UCLA/EC ENGR M146/Project/stage_3_cnn_classifier_part_1.ipynb Cell 43\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X63sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m hist \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(data, epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49mtest_data)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m    121\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[39m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/models/functional.py:274\u001b[0m, in \u001b[0;36m_adjust_input_rank\u001b[0;34m(self, flat_inputs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"sequential_19_1/Cast:0\", shape=(None,), dtype=float32). Expected shape (None, 1501, 161, 1), but input has incompatible shape (None,)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None,), dtype=string)\n  • training=True\n  • mask=None"
     ]
    }
   ],
   "source": [
    "hist = model.fit(data, epochs=20, validation_data=test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
