{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: CNN Classifier\n",
    "The manual approach, yielded some positive results\n",
    "Let's see if a machine learning algorithm using similar information might also work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plan:**\n",
    "\n",
    "Chord Qualities:\n",
    "1. Compute the summed frequency array, and note bin arrays\n",
    "2. Put these into a CNN (try different combinations)\n",
    "3. Try a few other models, including:\n",
    "    - random forest\n",
    "    - hmm\n",
    "    - knn\n",
    "\n",
    "Root Notes:\n",
    "1. Given the calculated quality and frequency volume, try to work out what the root note is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.io.wavfile import read as read_wav\n",
    "from scipy import fft,signal\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import tensorflow_io as tfio\n",
    "\n",
    "TONE_A = 440 \n",
    "NOTES = ['A','A#','B','C','C#','D','D#','E','F','F#','G','G#'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_to_rnote(freq):\n",
    "    r = 12.0*np.log2(freq/TONE_A)\n",
    "    return r\n",
    "\n",
    "def rnote_to_freq(r):\n",
    "    f = TONE_A*2**(r/12)\n",
    "    return f\n",
    "\n",
    "def get_note_volume(rnote,fft_image,fft_freq,rnote_epsilon=0.2):\n",
    "    \"\"\" rnote - name or number of note,fft_image - fourier image of signal,\n",
    "    fft_freq - frequencies in fft_image,rnote_epsilon - halfwide of window to inspect\n",
    "    return maximum volume(magnitude) of signal in freq window for rnote \"\"\"\n",
    "    if isinstance(rnote,str):\n",
    "        rnote = NOTES.index(rnote)\n",
    "    try:\n",
    "        f0 = rnote_to_freq(rnote-rnote_epsilon)\n",
    "        f1 = rnote_to_freq(rnote+rnote_epsilon)\n",
    "        f_idx = np.where((fft_freq>=f0)&(fft_freq<=f1)) \n",
    "        maxVol = np.max((fft_image[f_idx]))\n",
    "    except Exception:\n",
    "        return 0.\n",
    "    \n",
    "    return maxVol\n",
    "\n",
    "def get_notes_volume(rnote,fft_image,fft_freq,rnote_epsilon=0.5,oct_range_from=-4.,oct_range_to=8.):\n",
    "    if isinstance(rnote,str):\n",
    "        rnote = NOTES.index(rnote)\n",
    "    rnotes = np.arange(rnote+12.*oct_range_from,rnote+12.*oct_range_to,12.0)\n",
    "    vol = []\n",
    "    for rn in rnotes:\n",
    "        vol.append(get_note_volume(rn,fft_image,fft_freq))\n",
    "        \n",
    "    return np.max(vol)\n",
    "\n",
    "def plot_notes(fileName):\n",
    "    \"\"\"convert the fft image from file to notes notations and plot on\"\"\"\n",
    "    #print(fileName)\n",
    "    rate,data_raw = read_wav(fileName)\n",
    "    data = (data_raw[:,0]+data_raw[:,1]).astype(np.float32) # stereo of any type -> mono of float32\n",
    "    data = minmax_scale(data,(-1.,1.)) \n",
    "    fft_image = np.abs(fft.rfft(data,norm='forward')) \n",
    "    fft_freq = fft.rfftfreq(len(data),1./rate)\n",
    "    vol_matrix = np.ndarray(shape=(12),dtype=np.float32)\n",
    "    for rnote in range(12):\n",
    "        vol_matrix[rnote] = get_notes_volume(rnote,fft_image,fft_freq)\n",
    "        \n",
    "    plt.bar(NOTES, vol_matrix)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    File Path Root Note  Octave Quality  \\\n",
      "0        data/chords/dim/Eb-7-dim-chord-1.wav        Eb       7     dim   \n",
      "1   data/chords/min7b5/C-3-min7b5-chord-1.wav         C       3  min7b5   \n",
      "2       data/chords/dim7/E-6-dim7-chord-0.wav         E       6    dim7   \n",
      "3        data/chords/min/Bb-5-min-chord-0.wav        Bb       5     min   \n",
      "4  data/chords/maj7_2/Ab-5-maj7_2-chord-0.wav        Ab       5  maj7_2   \n",
      "\n",
      "   Inversion  \n",
      "0          1  \n",
      "1          1  \n",
      "2          0  \n",
      "3          0  \n",
      "4          0  \n"
     ]
    }
   ],
   "source": [
    "# try it out on a few of the files in /data/train_set.csv:\n",
    "train_set = pd.read_csv('data/train_set.csv')\n",
    "test_set = pd.read_csv('data/test_set.csv')\n",
    "print(train_set.head())\n",
    "\n",
    "# remove the chords that are not maj or min in the Quality column\n",
    "train_set = train_set[train_set['Quality'].isin(['maj', 'min', 'dim', 'aug'])]\n",
    "test_set = test_set[test_set['Quality'].isin(['maj', 'min', 'dim', 'aug'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aug' 'dim' 'maj' 'min']\n",
      "[1 3 2 0 0 3 2 1 3 1 3 2 3 0 0 0 3 3 1 1 2 1 2 1 2 2 2 0 1 2 2 0 0 0 1 0 0\n",
      " 1 1 0 2 0 0 1 2 3 0 3 1 0 0 1 1 1 2 1 2 0 3 3 3 0 2 1 1 1 2 0 2 2 1 2 0 0\n",
      " 3 1 2 2 0 2 0 1 3 3 3 3 3 2 1 1 2 3 3 0 3 3 3 1 3 3 2 2 0 0 1 2 0 2 1 1 1\n",
      " 2 2 2 3 3 3 3 2 3 0 1 1 0 3 2 1 3 0 2 3 0 2 2 0 0 0 0 3 1 2 2 1 1 2 2 1 2\n",
      " 2 3 0 3 0 0 1 0 1 2 3 1 3 2 3 1 2 3 2 2 2 0 2 3 3 3 1 1 3 3 3 1 0 0 1 0 3\n",
      " 1 3 0 0 3 1 1 0 0 1 1 0 0 0 2 0 0 2 3 1 3 3 3 3 0 2 1 3 3 3 1 2 0 3 0 3 1\n",
      " 0 0 0 1 0 0 1 1 0 3 1 1 1 0 0 0 3 1 3 1 3 2 2 2 2 3 3 2 0 1 2 3 0 1 1 2 3\n",
      " 0 0 1 2 2 1 3 3 0 3 2 3 2 1 1 0 1 1 2 0 3 0 3 2 0 0 0 0 1 0 2 2 2 1 2 3 1\n",
      " 2 3 0 1 3 0 1 3 2 1 0 0 3 3 2 3 2 0 2 1 3 3 2 1 1 2 0 2 1 1 0 0 3 2 3 0 0\n",
      " 3 0 1 0 3 2 2 2 1 0 0 0 3 2 0 3 0 3 0 3 3 0 0 3 1 2 3 2 0 2 1 2 0 1 0 0 3\n",
      " 0 2 2 1 0 1 0 1 0 1 2 1 1 2 0 1 0 3 2 2 2 1 0 2 3 2 1 0 0 0 0 1 3 2 0 2 3\n",
      " 3 3 2 1 2 2 3 1 1 1 0 2 3 1 0 2 1 3 2 3 1 3 2 1 1 3 3 1 2 2 3 0 0 3 3 3 2\n",
      " 3 0 3 0 3 0 0 3 1 2 3 3 3 0 1 0 3 3 1 1 2 1 2 0 3 0 1 3 3 3 2 1 3 0 1 0 0\n",
      " 2 1 3 0 2 3 0 2 3 3 0 2 1 1 1 3 2 2 3 2 1 1 1 1 2 1 2 2 1 0 1 0 3 2 1 1 2\n",
      " 1 2 3 3 0 3 2 1 3 0 1 2 2 0 2 1 3 0 0 1 3 0 1 3 3 0 2 1 1 1 2 3 1 2 0 2 1\n",
      " 1 1 0 0 0 1 3 1 0 2 0 2 2 3 0 1 0 1 1 0 0 2 3 0 1 3 2 2 3 0 1 2 3 0 3 0 2\n",
      " 2 2 2 2 2 1 3 1 3 3 1 1 0 2 0 2 0 2 2 3 2 3 1 2 0 1 3 3 0 2 1 0 3 0 1 2 0\n",
      " 3 0 1 2 3 3 2 2 3 2 3 1 2 1 1 3 1 3 2 2 0 1 2 2 2 2 0 0 3 0 0 1 3 0 1 0 1\n",
      " 0 1 2 3 3 0 2 3 2 1 1 1 3 2 0 2 3 3 1 3 0 3 3 0 2 2 2 3 0 2 1 1 0 3 1 1 3\n",
      " 2 2 1 1 2 1 0 1 2 3]\n",
      "[0 0 3 0 1 2 1 2 0 3 0 2 3 1 0 1 2 2 0 3 2 3 3 3 3 1 2 3 1 1 3 2 0 0 3 1 1\n",
      " 2 2 2 1 3 0 2 2 0 0 1 0 0 2 1 3 0 3 3 3 3 2 3 0 1 3 2 0 2 1 0 1 1 1 2 0 1\n",
      " 2 3 0 2 3 3 2 0 2 0 0 3 1 3 2 3 1 1 2 2 0 1 1 1 1 2 3 0 0 0 0 0 1 2 0 2 0\n",
      " 1 2 2 1 0 3 0 2 1 0 0 1 3 1 3 0 2 0 0 1 3 1 1 0 1 0 1 3 2 0 3 2 1 0 3 0 3\n",
      " 1 3 3 1 2 1 1 2 1 3 0 1 2 2 3 1 2 1 2 3 2 3 1 0 3 3 1 0 1 3 0 3 0 2 2 1 0\n",
      " 1 3 1 1 3 3 3 0 1 2 2 2 3 0 0 2 0 2 2 0 1 1 3 1 1 2 1 3 2 0 1 0 3 0 2 1 1\n",
      " 3 0 3 1 3 3 1 1 0 2 0 0 2 2 3 1 1 2 2 1 0 3 0 1 1 1 2 0 3 2 3 2 0 1 3 3 2\n",
      " 3 1 3 3 1 3 3 3 2 3 2 2 1 0 2 2 3 3 0 2 2 2 3 3 2 2 3 0 3 3 2 2 0 0 0 2 1\n",
      " 2 0 0 0 2 2 3 0 1 1 0]\n",
      "4\n",
      "4\n",
      "[0. 1. 0. 0.]\n",
      "[1. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adrianmcintosh/Library/Python/3.9/lib/python/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/adrianmcintosh/Desktop/UCLA/EC ENGR M146/Project/stage_3_cnn_classifier_part_1.ipynb Cell 19\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X22sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mprint\u001b[39m(test_set_one_hot[\u001b[39m0\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X22sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# fit the model using train_set_note_volumes and train_set_one_hot, but exclude the File Path, Quality, and Root Note columns\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X22sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_note_volumes\u001b[39m.\u001b[39;49mdrop(columns\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mQuality\u001b[39;49m\u001b[39m'\u001b[39;49m]), train_set_one_hot, epochs\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X22sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# evaluate on test_set\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X22sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m model\u001b[39m.\u001b[39mevaluate(test_note_volumes, test_set_one_hot)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m    121\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[39m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/framework/constant_op.py:103\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    102\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.float32)."
     ]
    }
   ],
   "source": [
    "\n",
    "# train_reshaped = train_set_note_volumes.reshape(train_set_note_volumes.shape[0], height, channels)\n",
    "# test_reshaped = test_set_note_volumes.reshape(train_set_note_volumes.shape[0], height, channels)\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "# Convert string inputs to numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_set_encoded = label_encoder.fit_transform(train_set[\"Quality\"])\n",
    "test_set_encoded = label_encoder.transform(test_set[\"Quality\"])\n",
    "\n",
    "# show the classes in train_set[\"Quality\"]\n",
    "print(label_encoder.classes_)\n",
    "\n",
    "# summarize the classes of train_set_encoded and test_set_encoded\n",
    "# count the number of classes in train_set_encoded and test_set_encoded\n",
    "print(train_set_encoded)\n",
    "print(test_set_encoded)\n",
    "\n",
    "print(len(np.unique(train_set_encoded)))\n",
    "print(len(np.unique(test_set_encoded)))\n",
    "\n",
    "# One-hot encode the numerical labels\n",
    "onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "train_set_one_hot = onehot_encoder.fit_transform(train_set_encoded.reshape(-1, 1))\n",
    "test_set_one_hot = onehot_encoder.transform(test_set_encoded.reshape(-1, 1))\n",
    "\n",
    "# Check the number of classes in train_set_one_hot and test_set_one_hot\n",
    "print(train_set_one_hot[0])\n",
    "print(test_set_one_hot[0])\n",
    "\n",
    "# fit the model using train_set_note_volumes and train_set_one_hot, but exclude the File Path, Quality, and Root Note columns\n",
    "model.fit(train_note_volumes.drop(columns=['Quality']), train_set_one_hot, epochs=3, batch_size=100)\n",
    "\n",
    "# evaluate on test_set\n",
    "model.evaluate(test_note_volumes, test_set_one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>A#</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>C#</th>\n",
       "      <th>D</th>\n",
       "      <th>D#</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>F#</th>\n",
       "      <th>G</th>\n",
       "      <th>G#</th>\n",
       "      <th>Quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>dim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.007999</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.005141</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>maj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>0.00356</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.002209</td>\n",
       "      <td>0.002292</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.002329</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>aug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.008392</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.005519</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>aug</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A        A#         B         C        C#         D        D#  \\\n",
       "0   0.00003  0.000025  0.000018  0.000055  0.000036  0.000027  0.000013   \n",
       "1  0.000044  0.000055  0.000015  0.000029  0.000035  0.000057  0.000049   \n",
       "2  0.000499  0.000167  0.000135  0.007999  0.000137   0.00011  0.005141   \n",
       "3  0.000124  0.000125  0.002133   0.00356  0.000071  0.000068  0.002209   \n",
       "4  0.000223  0.000155  0.008392  0.000298  0.000249  0.000301    0.0052   \n",
       "\n",
       "          E         F        F#         G        G# Quality  \n",
       "0  0.000015  0.000025  0.000013  0.000023  0.000039     dim  \n",
       "1  0.000026  0.000057  0.000043  0.000023  0.000062     min  \n",
       "2  0.000042   0.00003  0.000057    0.0023  0.002004     maj  \n",
       "3  0.002292  0.000042  0.000077  0.002329  0.002155     aug  \n",
       "4  0.000319  0.000039  0.000159  0.005519  0.000599     aug  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalise the data so that the volum\n",
    "train_set_one_hot\n",
    "len(train_set_one_hot)\n",
    "train_note_volumes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.18566775244299674"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try running random forrests on the data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=0)\n",
    "rf.fit(train_note_volumes.drop(columns=['Quality']), train_set_one_hot)\n",
    "preds = rf.predict(test_note_volumes.drop(columns=['Quality']))\n",
    "print(preds)\n",
    "accuracy_score(test_set_one_hot, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adrianmcintosh/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/dense.py:73: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/adrianmcintosh/Library/Python/3.9/lib/python/site-packages/keras/src/optimizers/base_optimizer.py:31: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.2162 - loss: 1.3865\n",
      "Epoch 2/3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.2269 - loss: 1.3861\n",
      "Epoch 3/3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2608 - loss: 1.3866 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x28c677640>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try running a neural network on the data\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=12))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_set.drop(columns=['File Path', 'Quality', 'Root Note', 'Octave', 'Inversion']), train_set_one_hot, epochs=3, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try running knn on the data\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(train_note_volumes.drop(columns=['Quality']), train_note_volumes['Quality'])\n",
    "preds = knn.predict(test_note_volumes.drop(columns=['Quality']))\n",
    "accuracy_score(test_set['Quality'], preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, The experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:A: object, A#: object, B: object, C: object, C#: object, D: object, D#: object, E: object, F: object, F#: object, G: object, G#: object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/adrianmcintosh/Desktop/UCLA/EC ENGR M146/Project/stage_3_cnn_classifier_part_1.ipynb Cell 25\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m xgb \u001b[39m=\u001b[39m XGBClassifier()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m xgb\u001b[39m.\u001b[39;49mfit(train_note_volumes\u001b[39m.\u001b[39;49mdrop(columns\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mQuality\u001b[39;49m\u001b[39m'\u001b[39;49m]), train_set[\u001b[39m'\u001b[39;49m\u001b[39mQuality\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m preds \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mpredict(test_note_volumes\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mQuality\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m accuracy_score(test_set[\u001b[39m'\u001b[39m\u001b[39mQuality\u001b[39m\u001b[39m'\u001b[39m], preds)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/sklearn.py:1496\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1485\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mnum_class\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_\n\u001b[1;32m   1487\u001b[0m (\n\u001b[1;32m   1488\u001b[0m     model,\n\u001b[1;32m   1489\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1494\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1495\u001b[0m )\n\u001b[0;32m-> 1496\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1497\u001b[0m     missing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmissing,\n\u001b[1;32m   1498\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m   1499\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m   1500\u001b[0m     group\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1501\u001b[0m     qid\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1502\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1503\u001b[0m     base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[1;32m   1504\u001b[0m     feature_weights\u001b[39m=\u001b[39;49mfeature_weights,\n\u001b[1;32m   1505\u001b[0m     eval_set\u001b[39m=\u001b[39;49meval_set,\n\u001b[1;32m   1506\u001b[0m     sample_weight_eval_set\u001b[39m=\u001b[39;49msample_weight_eval_set,\n\u001b[1;32m   1507\u001b[0m     base_margin_eval_set\u001b[39m=\u001b[39;49mbase_margin_eval_set,\n\u001b[1;32m   1508\u001b[0m     eval_group\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1509\u001b[0m     eval_qid\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1510\u001b[0m     create_dmatrix\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_dmatrix,\n\u001b[1;32m   1511\u001b[0m     enable_categorical\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menable_categorical,\n\u001b[1;32m   1512\u001b[0m     feature_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_types,\n\u001b[1;32m   1513\u001b[0m )\n\u001b[1;32m   1515\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1516\u001b[0m     params,\n\u001b[1;32m   1517\u001b[0m     train_dmatrix,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1526\u001b[0m     callbacks\u001b[39m=\u001b[39mcallbacks,\n\u001b[1;32m   1527\u001b[0m )\n\u001b[1;32m   1529\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/sklearn.py:534\u001b[0m, in \u001b[0;36m_wrap_evaluation_matrices\u001b[0;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, feature_types)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrap_evaluation_matrices\u001b[39m(\n\u001b[1;32m    515\u001b[0m     missing: \u001b[39mfloat\u001b[39m,\n\u001b[1;32m    516\u001b[0m     X: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    530\u001b[0m     feature_types: Optional[FeatureTypes],\n\u001b[1;32m    531\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Any, List[Tuple[Any, \u001b[39mstr\u001b[39m]]]:\n\u001b[1;32m    532\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Convert array_like evaluation matrices into DMatrix.  Perform validation on the\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[39m    way.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 534\u001b[0m     train_dmatrix \u001b[39m=\u001b[39m create_dmatrix(\n\u001b[1;32m    535\u001b[0m         data\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    536\u001b[0m         label\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    537\u001b[0m         group\u001b[39m=\u001b[39;49mgroup,\n\u001b[1;32m    538\u001b[0m         qid\u001b[39m=\u001b[39;49mqid,\n\u001b[1;32m    539\u001b[0m         weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    540\u001b[0m         base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[1;32m    541\u001b[0m         feature_weights\u001b[39m=\u001b[39;49mfeature_weights,\n\u001b[1;32m    542\u001b[0m         missing\u001b[39m=\u001b[39;49mmissing,\n\u001b[1;32m    543\u001b[0m         enable_categorical\u001b[39m=\u001b[39;49menable_categorical,\n\u001b[1;32m    544\u001b[0m         feature_types\u001b[39m=\u001b[39;49mfeature_types,\n\u001b[1;32m    545\u001b[0m         ref\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    546\u001b[0m     )\n\u001b[1;32m    548\u001b[0m     n_validation \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m eval_set \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mlen\u001b[39m(eval_set)\n\u001b[1;32m    550\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mvalidate_or_none\u001b[39m(meta: Optional[Sequence], name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Sequence:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/sklearn.py:954\u001b[0m, in \u001b[0;36mXGBModel._create_dmatrix\u001b[0;34m(self, ref, **kwargs)\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[39mif\u001b[39;00m _can_use_qdm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_method) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbooster \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgblinear\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    953\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 954\u001b[0m         \u001b[39mreturn\u001b[39;00m QuantileDMatrix(\n\u001b[1;32m    955\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs, ref\u001b[39m=\u001b[39;49mref, nthread\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs, max_bin\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_bin\n\u001b[1;32m    956\u001b[0m         )\n\u001b[1;32m    957\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:  \u001b[39m# `QuantileDMatrix` supports lesser types than DMatrix\u001b[39;00m\n\u001b[1;32m    958\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:1528\u001b[0m, in \u001b[0;36mQuantileDMatrix.__init__\u001b[0;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, max_bin, ref, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical, data_split_mode)\u001b[0m\n\u001b[1;32m   1508\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(\n\u001b[1;32m   1509\u001b[0m         info \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m         \u001b[39mfor\u001b[39;00m info \u001b[39min\u001b[39;00m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1521\u001b[0m         )\n\u001b[1;32m   1522\u001b[0m     ):\n\u001b[1;32m   1523\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1524\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mIf data iterator is used as input, data like label should be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1525\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mspecified as batch argument.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1526\u001b[0m         )\n\u001b[0;32m-> 1528\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init(\n\u001b[1;32m   1529\u001b[0m     data,\n\u001b[1;32m   1530\u001b[0m     ref\u001b[39m=\u001b[39;49mref,\n\u001b[1;32m   1531\u001b[0m     label\u001b[39m=\u001b[39;49mlabel,\n\u001b[1;32m   1532\u001b[0m     weight\u001b[39m=\u001b[39;49mweight,\n\u001b[1;32m   1533\u001b[0m     base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[1;32m   1534\u001b[0m     group\u001b[39m=\u001b[39;49mgroup,\n\u001b[1;32m   1535\u001b[0m     qid\u001b[39m=\u001b[39;49mqid,\n\u001b[1;32m   1536\u001b[0m     label_lower_bound\u001b[39m=\u001b[39;49mlabel_lower_bound,\n\u001b[1;32m   1537\u001b[0m     label_upper_bound\u001b[39m=\u001b[39;49mlabel_upper_bound,\n\u001b[1;32m   1538\u001b[0m     feature_weights\u001b[39m=\u001b[39;49mfeature_weights,\n\u001b[1;32m   1539\u001b[0m     feature_names\u001b[39m=\u001b[39;49mfeature_names,\n\u001b[1;32m   1540\u001b[0m     feature_types\u001b[39m=\u001b[39;49mfeature_types,\n\u001b[1;32m   1541\u001b[0m     enable_categorical\u001b[39m=\u001b[39;49menable_categorical,\n\u001b[1;32m   1542\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:1587\u001b[0m, in \u001b[0;36mQuantileDMatrix._init\u001b[0;34m(self, data, ref, enable_categorical, **meta)\u001b[0m\n\u001b[1;32m   1575\u001b[0m config \u001b[39m=\u001b[39m make_jcargs(\n\u001b[1;32m   1576\u001b[0m     nthread\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnthread, missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing, max_bin\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_bin\n\u001b[1;32m   1577\u001b[0m )\n\u001b[1;32m   1578\u001b[0m ret \u001b[39m=\u001b[39m _LIB\u001b[39m.\u001b[39mXGQuantileDMatrixCreateFromCallback(\n\u001b[1;32m   1579\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1580\u001b[0m     it\u001b[39m.\u001b[39mproxy\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1585\u001b[0m     ctypes\u001b[39m.\u001b[39mbyref(handle),\n\u001b[1;32m   1586\u001b[0m )\n\u001b[0;32m-> 1587\u001b[0m it\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m   1588\u001b[0m \u001b[39m# delay check_call to throw intermediate exception first\u001b[39;00m\n\u001b[1;32m   1589\u001b[0m _check_call(ret)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:575\u001b[0m, in \u001b[0;36mDataIter.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    573\u001b[0m exc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    574\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:556\u001b[0m, in \u001b[0;36mDataIter._handle_exception\u001b[0;34m(self, fn, dft_ret)\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[39mreturn\u001b[39;00m dft_ret\n\u001b[1;32m    555\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 556\u001b[0m     \u001b[39mreturn\u001b[39;00m fn()\n\u001b[1;32m    557\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    558\u001b[0m     \u001b[39m# Defer the exception in order to return 0 and stop the iteration.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m     \u001b[39m# Exception inside a ctype callback function has no effect except\u001b[39;00m\n\u001b[1;32m    560\u001b[0m     \u001b[39m# for printing to stderr (doesn't stop the execution).\u001b[39;00m\n\u001b[1;32m    561\u001b[0m     tb \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()[\u001b[39m2\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:640\u001b[0m, in \u001b[0;36mDataIter._next_wrapper.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_ref \u001b[39m=\u001b[39m ref\n\u001b[1;32m    639\u001b[0m \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m--> 640\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_exception(\u001b[39mlambda\u001b[39;00m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext(input_data), \u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/data.py:1280\u001b[0m, in \u001b[0;36mSingleBatchInternalIter.next\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m   1279\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mit \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1280\u001b[0m input_data(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n\u001b[1;32m   1281\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:623\u001b[0m, in \u001b[0;36mDataIter._next_wrapper.<locals>.input_data\u001b[0;34m(data, feature_names, feature_types, **kwargs)\u001b[0m\n\u001b[1;32m    621\u001b[0m     new, cat_codes, feature_names, feature_types \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_temporary_data\n\u001b[1;32m    622\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 623\u001b[0m     new, cat_codes, feature_names, feature_types \u001b[39m=\u001b[39m _proxy_transform(\n\u001b[1;32m    624\u001b[0m         data,\n\u001b[1;32m    625\u001b[0m         feature_names,\n\u001b[1;32m    626\u001b[0m         feature_types,\n\u001b[1;32m    627\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_enable_categorical,\n\u001b[1;32m    628\u001b[0m     )\n\u001b[1;32m    629\u001b[0m \u001b[39m# Stage the data, meta info are copied inside C++ MetaInfo.\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_temporary_data \u001b[39m=\u001b[39m (new, cat_codes, feature_names, feature_types)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/data.py:1315\u001b[0m, in \u001b[0;36m_proxy_transform\u001b[0;34m(data, feature_names, feature_types, enable_categorical)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data)\n\u001b[1;32m   1314\u001b[0m \u001b[39mif\u001b[39;00m _is_pandas_df(data):\n\u001b[0;32m-> 1315\u001b[0m     arr, feature_names, feature_types \u001b[39m=\u001b[39m _transform_pandas_df(\n\u001b[1;32m   1316\u001b[0m         data, enable_categorical, feature_names, feature_types\n\u001b[1;32m   1317\u001b[0m     )\n\u001b[1;32m   1318\u001b[0m     arr, _ \u001b[39m=\u001b[39m _ensure_np_dtype(arr, arr\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m   1319\u001b[0m     \u001b[39mreturn\u001b[39;00m arr, \u001b[39mNone\u001b[39;00m, feature_names, feature_types\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/data.py:490\u001b[0m, in \u001b[0;36m_transform_pandas_df\u001b[0;34m(data, enable_categorical, feature_names, feature_types, meta, meta_type)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[39mfor\u001b[39;00m dtype \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mdtypes:\n\u001b[1;32m    484\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\n\u001b[1;32m    485\u001b[0m         (dtype\u001b[39m.\u001b[39mname \u001b[39min\u001b[39;00m _pandas_dtype_mapper)\n\u001b[1;32m    486\u001b[0m         \u001b[39mor\u001b[39;00m is_pd_sparse_dtype(dtype)\n\u001b[1;32m    487\u001b[0m         \u001b[39mor\u001b[39;00m (is_pd_cat_dtype(dtype) \u001b[39mand\u001b[39;00m enable_categorical)\n\u001b[1;32m    488\u001b[0m         \u001b[39mor\u001b[39;00m is_pa_ext_dtype(dtype)\n\u001b[1;32m    489\u001b[0m     ):\n\u001b[0;32m--> 490\u001b[0m         _invalid_dataframe_dtype(data)\n\u001b[1;32m    491\u001b[0m     \u001b[39mif\u001b[39;00m is_pa_ext_dtype(dtype):\n\u001b[1;32m    492\u001b[0m         pyarrow_extension \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xgboost/data.py:308\u001b[0m, in \u001b[0;36m_invalid_dataframe_dtype\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    306\u001b[0m type_err \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDataFrame.dtypes for data must be int, float, bool or category.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\u001b[39m{\u001b[39;00mtype_err\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m_ENABLE_CAT_ERR\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00merr\u001b[39m}\u001b[39;00m\u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m--> 308\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, The experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:A: object, A#: object, B: object, C: object, C#: object, D: object, D#: object, E: object, F: object, F#: object, G: object, G#: object"
     ]
    }
   ],
   "source": [
    "# for every chord quality, set it to 0, 1, 2, 3\n",
    "train_set['Quality'] = train_set['Quality'].replace(['maj', 'min', 'dim', 'aug'], [0, 1, 2, 3])\n",
    "test_set['Quality'] = test_set['Quality'].replace(['maj', 'min', 'dim', 'aug'], [0, 1, 2, 3])\n",
    "\n",
    "# try running xgboost on the data\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(train_note_volumes.drop(columns=['Quality']), train_set['Quality'])\n",
    "preds = xgb.predict(test_note_volumes.drop(columns=['Quality']))\n",
    "accuracy_score(test_set['Quality'], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19543973941368079"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try running a naive bayes classifier on the data\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(train_set_note_volumes.drop(columns=['File Path', 'Quality', 'Root Note']), train_set['Quality'])\n",
    "preds = gnb.predict(test_set_note_volumes.drop(columns=['File Path', 'Quality', 'Root Note']))\n",
    "accuracy_score(test_set['Quality'], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model.evaluate(test_reshaped, test_set_one_hot)[1]\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50814332247557"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try running xgboost on the data\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(train_set_note_volumes.drop(columns=['File Path', 'Quality', 'Root Note']), train_set['Quality'])\n",
    "preds = xgb.predict(test_set_note_volumes.drop(columns=['File Path', 'Quality', 'Root Note']))\n",
    "accuracy_score(test_set['Quality'], preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/adrianmcintosh/Desktop/UCLA/EC ENGR M146/Project/stage_3_cnn_classifier_part_1.ipynb Cell 20\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X31sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m lr\u001b[39m.\u001b[39mfit(train_set_note_volumes\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mFile Path\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mQuality\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mRoot Note\u001b[39m\u001b[39m'\u001b[39m]), train_set[\u001b[39m'\u001b[39m\u001b[39mQuality\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X31sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m preds \u001b[39m=\u001b[39m lr\u001b[39m.\u001b[39mpredict(test_set_note_volumes\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mFile Path\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mQuality\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mRoot Note\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X31sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m accuracy_score(test_set[\u001b[39m'\u001b[39;49m\u001b[39mQuality\u001b[39;49m\u001b[39m'\u001b[39;49m], preds)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    215\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:220\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \n\u001b[1;32m    156\u001b[0m \u001b[39mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39m0.5\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[39m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 220\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    221\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    222\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m     92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     95\u001b[0m             type_true, type_pred\n\u001b[1;32m     96\u001b[0m         )\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     99\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    100\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "# try linear regression on the data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(train_set_note_volumes.drop(columns=['File Path', 'Quality', 'Root Note']), train_set['Quality'])\n",
    "preds = lr.predict(test_set_note_volumes.drop(columns=['File Path', 'Quality', 'Root Note']))\n",
    "accuracy_score(test_set['Quality'], preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "import scipy.signal as signal\n",
    "\n",
    "scheme = [\"min\", \"maj\", \"dim\", \"aug\"]\n",
    "\n",
    "def load_wav_16k_mono(filename):\n",
    "    sample_rate, wav_data = wav.read(filename)\n",
    "    if wav_data.ndim > 1:\n",
    "        wav_data = wav_data[:, 0]\n",
    "    return wav_data, sample_rate\n",
    "\n",
    "def preprocess(file_path, label):\n",
    "    wav_data, sample_rate = load_wav_16k_mono(file_path)\n",
    "    wav_data = wav_data[:48000]\n",
    "    zero_padding = np.zeros(48000 - len(wav_data), dtype=np.float32)\n",
    "    wav_data = np.concatenate([zero_padding, wav_data])\n",
    "    spectrogram = np.abs(signal.stft(wav_data, nperseg=320, noverlap=288)[2])\n",
    "    \n",
    "    # Add an extra dimension to the spectrogram before resizing\n",
    "    spectrogram = tf.expand_dims(spectrogram, axis=-1)\n",
    "    \n",
    "    # Ensure the spectrogram has the correct dimensions\n",
    "    spectrogram = tf.image.resize(spectrogram, [300, 500])\n",
    "\n",
    "    # crop the image\n",
    "\n",
    "    # set the one-hot encoding of the label\n",
    "    quality_one_hot = [0,0,0,0]\n",
    "    for i in range(len(scheme)):\n",
    "        if scheme[i] == label:\n",
    "            quality_one_hot[i] = 1\n",
    "\n",
    "    return spectrogram, quality_one_hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram, label = preprocess(train_set['File Path'].iloc[1], train_set['Quality'].iloc[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3000x2000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(30,20))\n",
    "plt.imshow(spectrogram)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the dimensions of spectrogram\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 75ms/step - accuracy: 0.9939 - loss: 0.0517\n",
      "Epoch 2/3\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 75ms/step - accuracy: 0.9684 - loss: 0.1675\n",
      "Epoch 3/3\n",
      "\u001b[1m713/713\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 2.1892e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x327a4a0d0>"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataset made up of the train_set and test_set dataframes respectively, where each row is a spectrogram and the label is the chord quality\n",
    "# this will be calculated using the preprocess function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Assuming train_set is your DataFrame\n",
    "file_paths = train_set['File Path'].to_numpy()\n",
    "qualities = train_set['Quality'].to_numpy()\n",
    "\n",
    "# Create a dataset using from_generator\n",
    "def generator():\n",
    "    for file_path, quality in zip(file_paths, qualities):\n",
    "        spectrogram, quality_one_hot = preprocess(file_path, quality)\n",
    "        spectrogram = tf.expand_dims(spectrogram, axis=0)\n",
    "        quality_one_hot = tf.expand_dims(quality_one_hot, axis=0)\n",
    "\n",
    "\n",
    "        yield spectrogram, tf.convert_to_tensor(np.array(quality_one_hot), dtype=tf.float32)\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(generator, output_signature=(\n",
    "    tf.TensorSpec(shape=(None, 161, 1501, 1), dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=(None,4), dtype=tf.float32)\n",
    "))\n",
    "\n",
    "# Assuming your model is defined as 'model'\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model using the dataset\n",
    "model.fit(dataset, epochs=3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create a model that takes in the spectrogram and outputs the chord quality\n",
    "# try a simple CNN model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m307/307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.4605 - loss: 4.3380\n",
      "Test loss: 4.65. Test accuracy: 41.37%\n"
     ]
    }
   ],
   "source": [
    "# test the model on the test_set\n",
    "\n",
    "# Assuming train_set is your DataFrame\n",
    "file_paths = test_set['File Path'].to_numpy()\n",
    "qualities = test_set['Quality'].to_numpy()\n",
    "\n",
    "# Create a dataset using from_generator\n",
    "def test_generator():\n",
    "    for file_path, quality in zip(file_paths, qualities):\n",
    "        spectrogram, quality_one_hot = preprocess(file_path, quality)\n",
    "        spectrogram = tf.expand_dims(spectrogram, axis=0)\n",
    "        quality_one_hot = tf.expand_dims(quality_one_hot, axis=0)\n",
    "\n",
    "\n",
    "        yield spectrogram, tf.convert_to_tensor(np.array(quality_one_hot), dtype=tf.float32)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_generator(test_generator, output_signature=(\n",
    "    tf.TensorSpec(shape=(None, 161, 1501, 1), dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=(None,4), dtype=tf.float32)\n",
    "))\n",
    "\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "print('Test loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Flatten, Dense, Dropout, MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming train_set is your DataFrame\n",
    "file_paths = train_set['File Path'].to_numpy()\n",
    "qualities = train_set['Quality'].to_numpy()\n",
    "\n",
    "# Create a dataset using from_generator\n",
    "def generator():\n",
    "    for file_path, quality in zip(file_paths, qualities):\n",
    "        spectrogram, quality_one_hot = preprocess(file_path, quality)\n",
    "        spectrogram = tf.expand_dims(spectrogram, axis=0)\n",
    "        quality_one_hot = tf.expand_dims(quality_one_hot, axis=0)\n",
    "\n",
    "\n",
    "        yield spectrogram, tf.convert_to_tensor(np.array(quality_one_hot), dtype=tf.float32)\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(generator, output_signature=(\n",
    "    tf.TensorSpec(shape=(None, 161, 1501, 1), dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=(None,4), dtype=tf.float32)\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adrianmcintosh/Library/Python/3.9/lib/python/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    570/Unknown \u001b[1m49s\u001b[0m 85ms/step - accuracy: 0.2505 - loss: 30.9712"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py:135: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(type, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 93ms/step - accuracy: 0.2505 - loss: 30.9304 - val_accuracy: 0.3077 - val_loss: 1.3623\n",
      "Epoch 2/10\n",
      "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 93ms/step - accuracy: 0.6145 - loss: 1.0665 - val_accuracy: 0.2867 - val_loss: 1.4229\n",
      "Epoch 3/10\n",
      "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 94ms/step - accuracy: 0.7452 - loss: 0.7385 - val_accuracy: 0.2308 - val_loss: 1.5510\n",
      "Epoch 4/10\n",
      "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 94ms/step - accuracy: 0.8257 - loss: 0.6415 - val_accuracy: 0.3147 - val_loss: 2.1933\n",
      "Epoch 5/10\n",
      "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 93ms/step - accuracy: 0.8264 - loss: 0.6185 - val_accuracy: 0.4196 - val_loss: 1.8858\n",
      "Epoch 6/10\n",
      "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 92ms/step - accuracy: 0.9622 - loss: 0.1869 - val_accuracy: 0.3986 - val_loss: 2.4392\n",
      "Epoch 7/10\n",
      "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 93ms/step - accuracy: 0.9681 - loss: 0.1307 - val_accuracy: 0.3776 - val_loss: 2.7320\n",
      "Epoch 8/10\n",
      "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 93ms/step - accuracy: 0.9903 - loss: 0.0356 - val_accuracy: 0.3916 - val_loss: 3.4387\n",
      "Epoch 9/10\n",
      "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 94ms/step - accuracy: 0.9886 - loss: 0.1070 - val_accuracy: 0.3986 - val_loss: 2.0947\n",
      "Epoch 10/10\n",
      "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 93ms/step - accuracy: 0.9829 - loss: 0.0756 - val_accuracy: 0.3497 - val_loss: 2.9162\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have loaded your data into X_train, y_train, X_test, y_test\n",
    "# Adjust the data loading according to your specific dataset.\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "# Assuming train_set is your DataFrame\n",
    "file_paths = train_set['File Path'].to_numpy()\n",
    "qualities = train_set['Quality'].to_numpy()\n",
    "\n",
    "# Create a dataset using from_generator\n",
    "def generator():\n",
    "    for file_path, quality in zip(file_paths, qualities):\n",
    "        spectrogram, quality_one_hot = preprocess(file_path, quality)\n",
    "        spectrogram = tf.expand_dims(spectrogram, axis=0)\n",
    "        quality_one_hot = tf.expand_dims(quality_one_hot, axis=0)\n",
    "\n",
    "\n",
    "        yield spectrogram, tf.convert_to_tensor(np.array(quality_one_hot), dtype=tf.float32)\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(generator, output_signature=(\n",
    "    tf.TensorSpec(shape=(None, 161, 1501, 1), dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=(None,4), dtype=tf.float32)\n",
    "))\n",
    "\n",
    "train_dataset = dataset.take(int(0.8 * 713))\n",
    "val_dataset = dataset.skip(int(0.8 * 713))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(161, 1501, 1)))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))  # Adjust the dropout rate as needed\n",
    "model.add(Dense(4, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with a validation set\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=10, batch_size=32,\n",
    "    validation_data=val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307/307 [==============================] - 3s 8ms/step - loss: 1.8028 - accuracy: 0.4137\n",
      "Test loss: 1.80. Test accuracy: 41.37%\n"
     ]
    }
   ],
   "source": [
    "# test the model on the test_set\n",
    "\n",
    "# Assuming train_set is your DataFrame\n",
    "file_paths = test_set['File Path'].to_numpy()\n",
    "qualities = test_set['Quality'].to_numpy()\n",
    "\n",
    "# Create a dataset using from_generator\n",
    "def test_generator():\n",
    "    for file_path, quality in zip(file_paths, qualities):\n",
    "        spectrogram, quality_one_hot = preprocess(file_path, quality)\n",
    "        spectrogram = tf.expand_dims(spectrogram, axis=0)\n",
    "        quality_one_hot = tf.expand_dims(quality_one_hot, axis=0)\n",
    "\n",
    "        yield spectrogram, tf.convert_to_tensor(np.array(quality_one_hot), dtype=tf.float32)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_generator(test_generator, output_signature=(\n",
    "    tf.TensorSpec(shape=(None, 300, 500, 1), dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=(None,4), dtype=tf.float32)\n",
    "))\n",
    "\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "print('Test loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all paths in train_set and test_set that have a # in it to replace the # with s\n",
    "train_set['File Path'] = train_set['File Path'].str.replace('#', 's')\n",
    "test_set['File Path'] = test_set['File Path'].str.replace('#', 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fold 1\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 139s 234ms/step - loss: 1.4350 - accuracy: 0.2256 - val_loss: 1.3894 - val_accuracy: 0.2353\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 140s 236ms/step - loss: 1.3924 - accuracy: 0.2407 - val_loss: 1.3879 - val_accuracy: 0.2353\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 138s 232ms/step - loss: 1.3911 - accuracy: 0.2593 - val_loss: 1.3881 - val_accuracy: 0.2353\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 139s 234ms/step - loss: 1.3911 - accuracy: 0.2542 - val_loss: 1.3883 - val_accuracy: 0.2353\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 138s 233ms/step - loss: 1.4203 - accuracy: 0.2593 - val_loss: 1.3935 - val_accuracy: 0.2353\n",
      "119/119 [==============================] - 7s 55ms/step - loss: 1.3935 - accuracy: 0.2353\n",
      "Fold 1 - Test Accuracy: 0.23529411852359772\n",
      "Training Fold 2\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 143s 241ms/step - loss: 1.4430 - accuracy: 0.2290 - val_loss: 1.3879 - val_accuracy: 0.2353\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 142s 238ms/step - loss: 1.3913 - accuracy: 0.2205 - val_loss: 1.3874 - val_accuracy: 0.2353\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 140s 235ms/step - loss: 1.3920 - accuracy: 0.2542 - val_loss: 1.3881 - val_accuracy: 0.2353\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 323s 545ms/step - loss: 1.3922 - accuracy: 0.2559 - val_loss: 1.3877 - val_accuracy: 0.2353\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 139s 235ms/step - loss: 1.3921 - accuracy: 0.2357 - val_loss: 1.3885 - val_accuracy: 0.2353\n",
      "119/119 [==============================] - 7s 56ms/step - loss: 1.3885 - accuracy: 0.2353\n",
      "Fold 2 - Test Accuracy: 0.23529411852359772\n",
      "Training Fold 3\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 139s 233ms/step - loss: 1.4459 - accuracy: 0.2407 - val_loss: 1.3878 - val_accuracy: 0.2353\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 141s 237ms/step - loss: 1.4144 - accuracy: 0.2340 - val_loss: 1.3893 - val_accuracy: 0.2353\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 141s 237ms/step - loss: 1.3970 - accuracy: 0.2475 - val_loss: 1.3886 - val_accuracy: 0.2353\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 144s 242ms/step - loss: 1.3907 - accuracy: 0.2391 - val_loss: 1.3877 - val_accuracy: 0.2353\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 143s 240ms/step - loss: 1.3964 - accuracy: 0.2323 - val_loss: 1.3903 - val_accuracy: 0.2353\n",
      "119/119 [==============================] - 7s 55ms/step - loss: 1.3903 - accuracy: 0.2353\n",
      "Fold 3 - Test Accuracy: 0.23529411852359772\n",
      "Training Fold 4\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 143s 241ms/step - loss: 1.4182 - accuracy: 0.2239 - val_loss: 1.3881 - val_accuracy: 0.2353\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 143s 240ms/step - loss: 1.3954 - accuracy: 0.2407 - val_loss: 1.3894 - val_accuracy: 0.2353\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 142s 240ms/step - loss: 1.4602 - accuracy: 0.2458 - val_loss: 1.4042 - val_accuracy: 0.2689\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 143s 241ms/step - loss: 1.4052 - accuracy: 0.2172 - val_loss: 1.3938 - val_accuracy: 0.2353\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 145s 243ms/step - loss: 1.3937 - accuracy: 0.2441 - val_loss: 1.3901 - val_accuracy: 0.2353\n",
      "119/119 [==============================] - 7s 58ms/step - loss: 1.3901 - accuracy: 0.2353\n",
      "Fold 4 - Test Accuracy: 0.23529411852359772\n",
      "Training Fold 5\n",
      "Epoch 1/5\n",
      "594/594 [==============================] - 146s 245ms/step - loss: 1.4174 - accuracy: 0.2391 - val_loss: 1.3887 - val_accuracy: 0.2353\n",
      "Epoch 2/5\n",
      "594/594 [==============================] - 142s 239ms/step - loss: 1.4036 - accuracy: 0.2357 - val_loss: 1.3882 - val_accuracy: 0.2353\n",
      "Epoch 3/5\n",
      "594/594 [==============================] - 147s 247ms/step - loss: 1.3906 - accuracy: 0.2256 - val_loss: 1.3873 - val_accuracy: 0.2353\n",
      "Epoch 4/5\n",
      "594/594 [==============================] - 145s 245ms/step - loss: 1.3897 - accuracy: 0.2492 - val_loss: 1.3876 - val_accuracy: 0.2353\n",
      "Epoch 5/5\n",
      "594/594 [==============================] - 142s 240ms/step - loss: 1.3917 - accuracy: 0.2559 - val_loss: 1.3898 - val_accuracy: 0.2353\n",
      "119/119 [==============================] - 7s 57ms/step - loss: 1.3898 - accuracy: 0.2353\n",
      "Fold 5 - Test Accuracy: 0.23529411852359772\n",
      "Training Fold 6\n",
      "Epoch 1/5\n",
      "595/595 [==============================] - 143s 240ms/step - loss: 1.4550 - accuracy: 0.2303 - val_loss: 1.3885 - val_accuracy: 0.2373\n",
      "Epoch 2/5\n",
      "595/595 [==============================] - 140s 235ms/step - loss: 1.3920 - accuracy: 0.2471 - val_loss: 1.3864 - val_accuracy: 0.2627\n",
      "Epoch 3/5\n",
      "595/595 [==============================] - 137s 230ms/step - loss: 1.3939 - accuracy: 0.2286 - val_loss: 1.3883 - val_accuracy: 0.2373\n",
      "Epoch 4/5\n",
      "595/595 [==============================] - 137s 230ms/step - loss: 1.3954 - accuracy: 0.2622 - val_loss: 1.3897 - val_accuracy: 0.2373\n",
      "Epoch 5/5\n",
      "595/595 [==============================] - 137s 230ms/step - loss: 1.3923 - accuracy: 0.2420 - val_loss: 1.3879 - val_accuracy: 0.2373\n",
      "118/118 [==============================] - 6s 54ms/step - loss: 1.3879 - accuracy: 0.2373\n",
      "Fold 6 - Test Accuracy: 0.23728813230991364\n"
     ]
    }
   ],
   "source": [
    "### 5-Fold Cross Validation ###\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Flatten, Dense, Dropout, MaxPooling2D, AvgPool2D\n",
    "\n",
    "# Assuming train_set is your DataFrame\n",
    "file_paths = train_set['File Path'].to_numpy()\n",
    "qualities = train_set['Quality'].to_numpy()\n",
    "\n",
    "# Create a dataset using from_generator\n",
    "def generator():\n",
    "    for file_path, quality in zip(file_paths, qualities):\n",
    "        spectrogram, quality_one_hot = preprocess(file_path, quality)\n",
    "        spectrogram = tf.expand_dims(spectrogram, axis=0)\n",
    "        quality_one_hot = tf.expand_dims(quality_one_hot, axis=0)\n",
    "\n",
    "        yield spectrogram, tf.convert_to_tensor(np.array(quality_one_hot), dtype=tf.float32)\n",
    "\n",
    "# Use KFold for 10-fold cross-validation\n",
    "kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
    "\n",
    "# Loop over folds\n",
    "# Loop over folds\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(file_paths, qualities)):\n",
    "    print(f\"Training Fold {fold + 1}\")\n",
    "\n",
    "    # Create training and validation datasets\n",
    "    train_dataset = tf.data.Dataset.from_generator(\n",
    "        generator, \n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(None, 300, 500, 1), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(None, 4), dtype=tf.float32)\n",
    "        )\n",
    "    ).take(len(train_index))  # Use len(train_index) to take all elements in the training set\n",
    "\n",
    "    val_dataset = tf.data.Dataset.from_generator(\n",
    "        generator,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(None, 300, 500, 1), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(None, 4), dtype=tf.float32)\n",
    "        )\n",
    "    ).take(len(val_index))  # Use len(val_index) to take all elements in the validation set\n",
    "\n",
    "    # Build and compile your model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(300, 500, 1)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='valid'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='valid'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 1), strides=None, padding='valid', data_format=None))\n",
    "    model.add(Dropout(0.5))  # Adjust the dropout rate as needed\n",
    "\n",
    "    # add a pool-max layer\n",
    "    model.add(MaxPooling2D(pool_size=(2, 1), strides=None, padding='valid', data_format=None))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 1), strides=None, data_format=None))\n",
    "    model.add(Dropout(0.5))  # Adjust the dropout rate as needed\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 1), strides=None, data_format=None))\n",
    "    model.add(Dropout(0.5))  # Adjust the dropout rate as needed\n",
    "    model.add(Conv2D(128, (12, 9), activation='relu'))\n",
    "    model.add(Dropout(0.5))  # Adjust the dropout rate as needed\n",
    "\n",
    "    model.add(Conv2D(25, (1, 1), activation='linear'))\n",
    "    model.add(AvgPool2D(pool_size=(6, 3), strides=None, padding='valid', data_format=None))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model on the current fold\n",
    "    model.fit(train_dataset, epochs=5, batch_size=32, validation_data=val_dataset)\n",
    "\n",
    "    # Evaluate the model on the test set or perform any other necessary actions\n",
    "    test_loss, test_accuracy = model.evaluate(val_dataset)\n",
    "    print(f\"Fold {fold + 1} - Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "\n",
    "# You can use the trained model for predictions or other tasks after the loop\n",
    "\n",
    "# test the model on the test_set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adrianmcintosh/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307/307 [==============================] - 3s 9ms/step - loss: 1.3891 - accuracy: 0.2476\n",
      "Test loss: 1.39. Test accuracy: 24.76%\n"
     ]
    }
   ],
   "source": [
    "# select model with best accuracy and save it\n",
    "# save the model\n",
    "model.save('model.h5')\n",
    "\n",
    "# load the model\n",
    "from keras.models import load_model\n",
    "model = load_model('model.h5')\n",
    "\n",
    "# test the model on the test_set\n",
    "\n",
    "# Assuming train_set is your DataFrame\n",
    "file_paths = test_set['File Path'].to_numpy()\n",
    "qualities = test_set['Quality'].to_numpy()\n",
    "\n",
    "# Create a dataset using from_generator\n",
    "\n",
    "def test_generator():\n",
    "    for file_path, quality in zip(file_paths, qualities):\n",
    "        spectrogram, quality_one_hot = preprocess(file_path, quality)\n",
    "        spectrogram = tf.expand_dims(spectrogram, axis=0)\n",
    "        quality_one_hot = tf.expand_dims(quality_one_hot, axis=0)\n",
    "\n",
    "        yield spectrogram, tf.convert_to_tensor(np.array(quality_one_hot), dtype=tf.float32)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_generator(test_generator, output_signature=(\n",
    "    tf.TensorSpec(shape=(None, 300, 500, 1), dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=(None,4), dtype=tf.float32)\n",
    "))\n",
    "\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "print('Test loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "570/570 [==============================] - 23s 41ms/step - loss: 8.0655 - accuracy: 0.2509 - val_loss: 1.3835 - val_accuracy: 0.2657\n",
      "Epoch 2/10\n",
      "570/570 [==============================] - 27s 48ms/step - loss: 1.2485 - accuracy: 0.4754 - val_loss: 1.3855 - val_accuracy: 0.2308\n",
      "Epoch 3/10\n",
      "570/570 [==============================] - 28s 49ms/step - loss: 1.0501 - accuracy: 0.6193 - val_loss: 1.4243 - val_accuracy: 0.2937\n",
      "Epoch 4/10\n",
      "570/570 [==============================] - 24s 42ms/step - loss: 0.7792 - accuracy: 0.7386 - val_loss: 2.0487 - val_accuracy: 0.3497\n",
      "Epoch 5/10\n",
      "570/570 [==============================] - 23s 40ms/step - loss: 0.4291 - accuracy: 0.8737 - val_loss: 2.1408 - val_accuracy: 0.3147\n",
      "Epoch 6/10\n",
      "570/570 [==============================] - 23s 41ms/step - loss: 0.2018 - accuracy: 0.9579 - val_loss: 1.5796 - val_accuracy: 0.3706\n",
      "Epoch 7/10\n",
      "570/570 [==============================] - 23s 40ms/step - loss: 0.1123 - accuracy: 0.9719 - val_loss: 1.4408 - val_accuracy: 0.3986\n",
      "Epoch 8/10\n",
      "570/570 [==============================] - 23s 41ms/step - loss: 0.0413 - accuracy: 0.9930 - val_loss: 1.4315 - val_accuracy: 0.3916\n",
      "Epoch 9/10\n",
      "570/570 [==============================] - 24s 43ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 2.3796 - val_accuracy: 0.3916\n",
      "Epoch 10/10\n",
      "570/570 [==============================] - 24s 42ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 2.2507 - val_accuracy: 0.4126\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have loaded your data into X_train, y_train, X_test, y_test\n",
    "# Adjust the data loading according to your specific dataset.\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "# Assuming train_set is your DataFrame\n",
    "import PoolMax2D from keras.layers\n",
    "\n",
    "\n",
    "file_paths = train_set['File Path'].to_numpy()\n",
    "qualities = train_set['Quality'].to_numpy()\n",
    "\n",
    "# Create a dataset using from_generator\n",
    "def generator():\n",
    "    for file_path, quality in zip(file_paths, qualities):\n",
    "        spectrogram, quality_one_hot = preprocess(file_path, quality)\n",
    "        spectrogram = tf.expand_dims(spectrogram, axis=0)\n",
    "        quality_one_hot = tf.expand_dims(quality_one_hot, axis=0)\n",
    "\n",
    "\n",
    "        yield spectrogram, tf.convert_to_tensor(np.array(quality_one_hot), dtype=tf.float32)\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(generator, output_signature=(\n",
    "    tf.TensorSpec(shape=(None, 300, 500, 1), dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=(None,4), dtype=tf.float32)\n",
    "))\n",
    "\n",
    "train_dataset = dataset.take(int(0.8 * 713))\n",
    "val_dataset = dataset.skip(int(0.8 * 713))\n",
    "\n",
    "model = Sequential()\n",
    "# add a convolutional layer, recti\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(300, 500, 1)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='valid'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='valid')))\n",
    "model.add(PoolMax2D(pool_size=(2, 1), strides=None, padding='valid', data_format=None))\n",
    "model.add(Dropout(0.5))  # Adjust the dropout rate as needed\n",
    "\n",
    "# add a pool-max layer\n",
    "model.add(PoolMax2D(pool_size=(2, 1), strides=None, padding='valid', data_format=None))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 1), strides=None, data_format=None))\n",
    "model.add(Dropout(0.5))  # Adjust the dropout rate as needed\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 1), strides=None, data_format=None))\n",
    "model.add(Dropout(0.5))  # Adjust the dropout rate as needed\n",
    "model.add(Conv2D(128, (12, 9), activation='relu'))\n",
    "\n",
    "model.add(Conv2D(25, (1, 1), activation='linear'))\n",
    "model.add(AvgPool2D(pool_size=(13, 3), strides=None, padding='valid', data_format=None))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with a validation set\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=10, batch_size=32,\n",
    "    validation_data=val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307/307 [==============================] - 3s 8ms/step - loss: 2.0562 - accuracy: 0.4463\n",
      "Test loss: 2.06. Test accuracy: 44.63%\n"
     ]
    }
   ],
   "source": [
    "# Assuming train_set is your DataFrame\n",
    "file_paths = test_set['File Path'].to_numpy()\n",
    "qualities = test_set['Quality'].to_numpy()\n",
    "\n",
    "# Create a dataset using from_generator\n",
    "\n",
    "def test_generator():\n",
    "    for file_path, quality in zip(file_paths, qualities):\n",
    "        spectrogram, quality_one_hot = preprocess(file_path, quality)\n",
    "        spectrogram = tf.expand_dims(spectrogram, axis=0)\n",
    "        quality_one_hot = tf.expand_dims(quality_one_hot, axis=0)\n",
    "\n",
    "        yield spectrogram, tf.convert_to_tensor(np.array(quality_one_hot), dtype=tf.float32)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_generator(test_generator, output_signature=(\n",
    "    tf.TensorSpec(shape=(None, 300, 500, 1), dtype=tf.float32),\n",
    "    tf.TensorSpec(shape=(None,4), dtype=tf.float32)\n",
    "))\n",
    "\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "print('Test loss: {0:.2f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
