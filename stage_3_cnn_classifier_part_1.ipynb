{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: CNN Classifier\n",
    "The manual approach, yielded some positive results\n",
    "Let's see if a machine learning algorithm using similar information might also work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plan:**\n",
    "\n",
    "Chord Qualities:\n",
    "1. Compute the summed frequency array, and note bin arrays\n",
    "2. Put these into a CNN (try different combinations)\n",
    "3. Try a few other models, including:\n",
    "    - random forest\n",
    "    - hmm\n",
    "    - knn\n",
    "\n",
    "Root Notes:\n",
    "1. Given the calculated quality and frequency volume, try to work out what the root note is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.io.wavfile import read as read_wav\n",
    "from scipy import fft,signal\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "TONE_A = 440 \n",
    "NOTES = ['A','A#','B','C','C#','D','D#','E','F','F#','G','G#'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_to_rnote(freq):\n",
    "    r = 12.0*np.log2(freq/TONE_A)\n",
    "    return r\n",
    "\n",
    "def rnote_to_freq(r):\n",
    "    f = TONE_A*2**(r/12)\n",
    "    return f\n",
    "\n",
    "def get_note_volume(rnote,fft_image,fft_freq,rnote_epsilon=0.2):\n",
    "    \"\"\" rnote - name or number of note,fft_image - fourier image of signal,\n",
    "    fft_freq - frequencies in fft_image,rnote_epsilon - halfwide of window to inspect\n",
    "    return maximum volume(magnitude) of signal in freq window for rnote \"\"\"\n",
    "    if isinstance(rnote,str):\n",
    "        rnote = NOTES.index(rnote)\n",
    "    try:\n",
    "        f0 = rnote_to_freq(rnote-rnote_epsilon)\n",
    "        f1 = rnote_to_freq(rnote+rnote_epsilon)\n",
    "        f_idx = np.where((fft_freq>=f0)&(fft_freq<=f1)) \n",
    "        maxVol = np.max((fft_image[f_idx]))\n",
    "    except Exception:\n",
    "        return 0.\n",
    "    \n",
    "    return maxVol\n",
    "\n",
    "def get_notes_volume(rnote,fft_image,fft_freq,rnote_epsilon=0.5,oct_range_from=-4.,oct_range_to=8.):\n",
    "    if isinstance(rnote,str):\n",
    "        rnote = NOTES.index(rnote)\n",
    "    rnotes = np.arange(rnote+12.*oct_range_from,rnote+12.*oct_range_to,12.0)\n",
    "    vol = []\n",
    "    for rn in rnotes:\n",
    "        vol.append(get_note_volume(rn,fft_image,fft_freq))\n",
    "        \n",
    "    return np.max(vol)\n",
    "\n",
    "def plot_notes(fileName):\n",
    "    \"\"\"convert the fft image from file to notes notations and plot on\"\"\"\n",
    "    #print(fileName)\n",
    "    rate,data_raw = read_wav(fileName)\n",
    "    data = (data_raw[:,0]+data_raw[:,1]).astype(np.float32) # stereo of any type -> mono of float32\n",
    "    data = minmax_scale(data,(-1.,1.)) \n",
    "    fft_image = np.abs(fft.rfft(data,norm='forward')) \n",
    "    fft_freq = fft.rfftfreq(len(data),1./rate)\n",
    "    vol_matrix = np.ndarray(shape=(12),dtype=np.float32)\n",
    "    for rnote in range(12):\n",
    "        vol_matrix[rnote] = get_notes_volume(rnote,fft_image,fft_freq)\n",
    "        \n",
    "    plt.bar(NOTES, vol_matrix)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    File Path Root Note  Octave Quality  \\\n",
      "0        data/chords/dim/Eb-7-dim-chord-1.wav        Eb       7     dim   \n",
      "1   data/chords/min7b5/C-3-min7b5-chord-1.wav         C       3  min7b5   \n",
      "2       data/chords/dim7/E-6-dim7-chord-0.wav         E       6    dim7   \n",
      "3        data/chords/min/Bb-5-min-chord-0.wav        Bb       5     min   \n",
      "4  data/chords/maj7_2/Ab-5-maj7_2-chord-0.wav        Ab       5  maj7_2   \n",
      "\n",
      "   Inversion  \n",
      "0          1  \n",
      "1          1  \n",
      "2          0  \n",
      "3          0  \n",
      "4          0  \n"
     ]
    }
   ],
   "source": [
    "# try it out on a few of the files in /data/train_set.csv:\n",
    "train_set = pd.read_csv('data/train_set.csv')\n",
    "test_set = pd.read_csv('data/test_set.csv')\n",
    "print(train_set.head())\n",
    "\n",
    "# remove the chords that are not maj or min in the Quality column\n",
    "train_set = train_set[train_set['Quality'].isin(['maj', 'min', 'dim', 'aug'])]\n",
    "test_set = test_set[test_set['Quality'].isin(['maj', 'min', 'dim', 'aug'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         File Path  Root Note  Octave  Inversion\n",
      "Quality                                         \n",
      "aug            179        179     179        179\n",
      "dim            178        178     178        178\n",
      "maj            178        178     178        178\n",
      "min            178        178     178        178\n",
      "         File Path  Root Note  Octave  Inversion\n",
      "Quality                                         \n",
      "aug             76         76      76         76\n",
      "dim             77         77      77         77\n",
      "maj             77         77      77         77\n",
      "min             77         77      77         77\n"
     ]
    }
   ],
   "source": [
    "print(train_set.groupby(['Quality']).count())\n",
    "print(test_set.groupby(['Quality']).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     713\n",
       "unique      4\n",
       "top       aug\n",
       "freq      179\n",
       "Name: Quality, dtype: object"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)\n",
    "# summarise the data\n",
    "train_set['Quality'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 713/713 [00:01<00:00, 411.76it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 385.69it/s]\n"
     ]
    }
   ],
   "source": [
    "# preprocessing:\n",
    "def preprocess(fileName):\n",
    "    rate, data_raw = read_wav(fileName)\n",
    "    data = (data_raw[:,0]+data_raw[:,1]).astype(np.float32) # stereo of any type -> mono of float32\n",
    "    data = minmax_scale(data,(-1.,1.))\n",
    "    fft_image = np.abs(fft.rfft(data,norm='forward'))\n",
    "    fft_freq = fft.rfftfreq(len(data),1./rate)\n",
    "    note_volumes = []\n",
    "    for note in NOTES:        \n",
    "    \n",
    "        note_volumes.append(get_note_volume(note,fft_image,fft_freq))\n",
    "    # print(note_volumes)\n",
    "    \n",
    "    return note_volumes\n",
    "\n",
    "# create a new dataframe with the note volumes\n",
    "train_note_volumes = pd.DataFrame(columns=NOTES)\n",
    "test_note_volumes = pd.DataFrame(columns=NOTES)    \n",
    "\n",
    "for i in tqdm(range(len(train_set))):\n",
    "    fileName = train_set['File Path'].iloc[i]\n",
    "    note_volumes = preprocess(fileName)\n",
    "    # print the shape of note_volumes\n",
    "    # print(note_volumes.shape)\n",
    "    for j in range(len(note_volumes)):\n",
    "        train_note_volumes.at[i, NOTES[j]] = note_volumes[j]\n",
    "\n",
    "for i in tqdm(range(len(test_set))):\n",
    "    fileName = test_set['File Path'].iloc[i]\n",
    "    note_volumes = preprocess(fileName)\n",
    "    for j in range(len(note_volumes)):\n",
    "        test_note_volumes.at[i, NOTES[j]] = note_volumes[j]\n",
    "        # test_set.iloc[i][NOTES[j]] = note_volumes[j]\n",
    "        # test_set.at[i, NOTES[j]] = note_volumes[j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "713"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# summarise the quality column in train_set\n",
    "train_set['Quality'].describe()\n",
    "\n",
    "# show each quality in train_set and how many there are\n",
    "train_set.groupby(['Quality']).count()\n",
    "\n",
    "\n",
    "# how many nan values are there in the train_set?\n",
    "\n",
    "# add the qualities to the note_volumes dataframe\n",
    "# train_note_volumes['Quality'] = train_set['Quality']\n",
    "# test_note_volumes['Quality'] = test_set['Quality']\n",
    "\n",
    "len(train_note_volumes)\n",
    "\n",
    "\n",
    "# print(train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>A#</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>C#</th>\n",
       "      <th>D</th>\n",
       "      <th>D#</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>F#</th>\n",
       "      <th>G</th>\n",
       "      <th>G#</th>\n",
       "      <th>Quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>dim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.007999</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.005141</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>maj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>0.00356</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.002209</td>\n",
       "      <td>0.002292</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.002329</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>aug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.008392</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.005519</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>aug</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A        A#         B         C        C#         D        D#  \\\n",
       "0   0.00003  0.000025  0.000018  0.000055  0.000036  0.000027  0.000013   \n",
       "1  0.000044  0.000055  0.000015  0.000029  0.000035  0.000057  0.000049   \n",
       "2  0.000499  0.000167  0.000135  0.007999  0.000137   0.00011  0.005141   \n",
       "3  0.000124  0.000125  0.002133   0.00356  0.000071  0.000068  0.002209   \n",
       "4  0.000223  0.000155  0.008392  0.000298  0.000249  0.000301    0.0052   \n",
       "\n",
       "          E         F        F#         G        G# Quality  \n",
       "0  0.000015  0.000025  0.000013  0.000023  0.000039     dim  \n",
       "1  0.000026  0.000057  0.000043  0.000023  0.000062     min  \n",
       "2  0.000042   0.00003  0.000057    0.0023  0.002004     maj  \n",
       "3  0.002292  0.000042  0.000077  0.002329  0.002155     aug  \n",
       "4  0.000319  0.000039  0.000159  0.005519  0.000599     aug  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_note_volumes['Quality'].isnull().sum()\n",
    "train_note_volumes['Quality'].describe()\n",
    "train_note_volumes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               File Path Root Note  Octave Quality  Inversion  \\\n",
      "0   data/chords/dim/Eb-7-dim-chord-1.wav        Eb       7     dim          1   \n",
      "3   data/chords/min/Bb-5-min-chord-0.wav        Bb       5     min          0   \n",
      "20  data/chords/maj/Ab-3-maj-chord-1.wav        Ab       3     maj          1   \n",
      "28  data/chords/aug/Ab-2-aug-chord-0.wav        Ab       2     aug          0   \n",
      "32   data/chords/aug/G-4-aug-chord-1.wav         G       4     aug          1   \n",
      "\n",
      "           A        A#         B         C        C#         D        D#  \\\n",
      "0   0.000693  0.030367  0.000416  0.000121  0.009097  0.000226  0.000272   \n",
      "3   0.000693  0.030367  0.000416  0.000121  0.009097  0.000226  0.000272   \n",
      "20  0.000693  0.030367  0.000416  0.000121  0.009097  0.000226  0.000272   \n",
      "28  0.000693  0.030367  0.000416  0.000121  0.009097  0.000226  0.000272   \n",
      "32  0.000693  0.030367  0.000416  0.000121  0.009097  0.000226  0.000272   \n",
      "\n",
      "           E         F        F#         G        G#  \n",
      "0   0.000194  0.004041  0.000067  0.000041  0.000066  \n",
      "3   0.000194  0.004041  0.000067  0.000041  0.000066  \n",
      "20  0.000194  0.004041  0.000067  0.000041  0.000066  \n",
      "28  0.000194  0.004041  0.000067  0.000041  0.000066  \n",
      "32  0.000194  0.004041  0.000067  0.000041  0.000066  \n",
      "                               File Path Root Note  Octave Quality  Inversion  \\\n",
      "0   data/chords/dim/Eb-7-dim-chord-1.wav        Eb       7     dim          1   \n",
      "3   data/chords/min/Bb-5-min-chord-0.wav        Bb       5     min          0   \n",
      "20  data/chords/maj/Ab-3-maj-chord-1.wav        Ab       3     maj          1   \n",
      "28  data/chords/aug/Ab-2-aug-chord-0.wav        Ab       2     aug          0   \n",
      "32   data/chords/aug/G-4-aug-chord-1.wav         G       4     aug          1   \n",
      "\n",
      "      A   A#    B    C   C#    D   D#    E    F   F#    G   G#  \n",
      "0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "20  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "28  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "32  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Assuming df is your DataFrame and it's already been normalized row-wise\n",
    "\n",
    "# Create a scaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the data but not for the 'File Path', Inversion, Root Note, Quality, and Chord Name columns\n",
    "\n",
    "columns_to_scale = train_set.drop(columns=['File Path', 'Quality', 'Root Note', 'Octave', 'Inversion']).columns\n",
    "train_set[columns_to_scale] = scaler.fit_transform(train_set[columns_to_scale])\n",
    "\n",
    "print(train_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dim' 'min' 'maj' 'aug']\n",
      "713\n"
     ]
    }
   ],
   "source": [
    "print(train_note_volumes['Quality'].unique())\n",
    "print(len(train_set))\n",
    "# remove the chords that have nan values in train_set\n",
    "train_set = train_set.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adrianmcintosh/Library/Python/3.9/lib/python/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "# run a CNN on the data, using the note volumes as the input and the chord quality as the output\n",
    "# Path: stage_3_cnn_classifier_part_2.ipynb\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "\n",
    "num_classes = 4\n",
    "height = 12\n",
    "width = 1\n",
    "channels = 1\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Add Convolutional layers\n",
    "model.add(Conv1D(32, 3, activation='relu', input_shape=(height, channels)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Conv1D(32, 3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# Flatten the output to feed into dense layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add Dense layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aug' 'dim' 'maj' 'min']\n",
      "[1 3 2 0 0 3 2 1 3 1 3 2 3 0 0 0 3 3 1 1 2 1 2 1 2 2 2 0 1 2 2 0 0 0 1 0 0\n",
      " 1 1 0 2 0 0 1 2 3 0 3 1 0 0 1 1 1 2 1 2 0 3 3 3 0 2 1 1 1 2 0 2 2 1 2 0 0\n",
      " 3 1 2 2 0 2 0 1 3 3 3 3 3 2 1 1 2 3 3 0 3 3 3 1 3 3 2 2 0 0 1 2 0 2 1 1 1\n",
      " 2 2 2 3 3 3 3 2 3 0 1 1 0 3 2 1 3 0 2 3 0 2 2 0 0 0 0 3 1 2 2 1 1 2 2 1 2\n",
      " 2 3 0 3 0 0 1 0 1 2 3 1 3 2 3 1 2 3 2 2 2 0 2 3 3 3 1 1 3 3 3 1 0 0 1 0 3\n",
      " 1 3 0 0 3 1 1 0 0 1 1 0 0 0 2 0 0 2 3 1 3 3 3 3 0 2 1 3 3 3 1 2 0 3 0 3 1\n",
      " 0 0 0 1 0 0 1 1 0 3 1 1 1 0 0 0 3 1 3 1 3 2 2 2 2 3 3 2 0 1 2 3 0 1 1 2 3\n",
      " 0 0 1 2 2 1 3 3 0 3 2 3 2 1 1 0 1 1 2 0 3 0 3 2 0 0 0 0 1 0 2 2 2 1 2 3 1\n",
      " 2 3 0 1 3 0 1 3 2 1 0 0 3 3 2 3 2 0 2 1 3 3 2 1 1 2 0 2 1 1 0 0 3 2 3 0 0\n",
      " 3 0 1 0 3 2 2 2 1 0 0 0 3 2 0 3 0 3 0 3 3 0 0 3 1 2 3 2 0 2 1 2 0 1 0 0 3\n",
      " 0 2 2 1 0 1 0 1 0 1 2 1 1 2 0 1 0 3 2 2 2 1 0 2 3 2 1 0 0 0 0 1 3 2 0 2 3\n",
      " 3 3 2 1 2 2 3 1 1 1 0 2 3 1 0 2 1 3 2 3 1 3 2 1 1 3 3 1 2 2 3 0 0 3 3 3 2\n",
      " 3 0 3 0 3 0 0 3 1 2 3 3 3 0 1 0 3 3 1 1 2 1 2 0 3 0 1 3 3 3 2 1 3 0 1 0 0\n",
      " 2 1 3 0 2 3 0 2 3 3 0 2 1 1 1 3 2 2 3 2 1 1 1 1 2 1 2 2 1 0 1 0 3 2 1 1 2\n",
      " 1 2 3 3 0 3 2 1 3 0 1 2 2 0 2 1 3 0 0 1 3 0 1 3 3 0 2 1 1 1 2 3 1 2 0 2 1\n",
      " 1 1 0 0 0 1 3 1 0 2 0 2 2 3 0 1 0 1 1 0 0 2 3 0 1 3 2 2 3 0 1 2 3 0 3 0 2\n",
      " 2 2 2 2 2 1 3 1 3 3 1 1 0 2 0 2 0 2 2 3 2 3 1 2 0 1 3 3 0 2 1 0 3 0 1 2 0\n",
      " 3 0 1 2 3 3 2 2 3 2 3 1 2 1 1 3 1 3 2 2 0 1 2 2 2 2 0 0 3 0 0 1 3 0 1 0 1\n",
      " 0 1 2 3 3 0 2 3 2 1 1 1 3 2 0 2 3 3 1 3 0 3 3 0 2 2 2 3 0 2 1 1 0 3 1 1 3\n",
      " 2 2 1 1 2 1 0 1 2 3]\n",
      "[0 0 3 0 1 2 1 2 0 3 0 2 3 1 0 1 2 2 0 3 2 3 3 3 3 1 2 3 1 1 3 2 0 0 3 1 1\n",
      " 2 2 2 1 3 0 2 2 0 0 1 0 0 2 1 3 0 3 3 3 3 2 3 0 1 3 2 0 2 1 0 1 1 1 2 0 1\n",
      " 2 3 0 2 3 3 2 0 2 0 0 3 1 3 2 3 1 1 2 2 0 1 1 1 1 2 3 0 0 0 0 0 1 2 0 2 0\n",
      " 1 2 2 1 0 3 0 2 1 0 0 1 3 1 3 0 2 0 0 1 3 1 1 0 1 0 1 3 2 0 3 2 1 0 3 0 3\n",
      " 1 3 3 1 2 1 1 2 1 3 0 1 2 2 3 1 2 1 2 3 2 3 1 0 3 3 1 0 1 3 0 3 0 2 2 1 0\n",
      " 1 3 1 1 3 3 3 0 1 2 2 2 3 0 0 2 0 2 2 0 1 1 3 1 1 2 1 3 2 0 1 0 3 0 2 1 1\n",
      " 3 0 3 1 3 3 1 1 0 2 0 0 2 2 3 1 1 2 2 1 0 3 0 1 1 1 2 0 3 2 3 2 0 1 3 3 2\n",
      " 3 1 3 3 1 3 3 3 2 3 2 2 1 0 2 2 3 3 0 2 2 2 3 3 2 2 3 0 3 3 2 2 0 0 0 2 1\n",
      " 2 0 0 0 2 2 3 0 1 1 0]\n",
      "4\n",
      "4\n",
      "[0. 1. 0. 0.]\n",
      "[1. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adrianmcintosh/Library/Python/3.9/lib/python/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/adrianmcintosh/Desktop/UCLA/EC ENGR M146/Project/stage_3_cnn_classifier_part_1.ipynb Cell 19\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X22sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mprint\u001b[39m(test_set_one_hot[\u001b[39m0\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X22sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# # fit the model using train_set_note_volumes and train_set_one_hot, but exclude the File Path, Quality, and Root Note columns\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X22sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_note_volumes\u001b[39m.\u001b[39;49mdrop(columns\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mQuality\u001b[39;49m\u001b[39m'\u001b[39;49m]), train_set_one_hot, epochs\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X22sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# # evaluate on test_set\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X22sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m model\u001b[39m.\u001b[39mevaluate(test_set\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mFile Path\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mQuality\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mRoot Note\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mOctave\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mInversion\u001b[39m\u001b[39m'\u001b[39m]), test_set_one_hot)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m    121\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[39m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/framework/constant_op.py:103\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    102\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.float32)."
     ]
    }
   ],
   "source": [
    "\n",
    "# train_reshaped = train_set_note_volumes.reshape(train_set_note_volumes.shape[0], height, channels)\n",
    "# test_reshaped = test_set_note_volumes.reshape(train_set_note_volumes.shape[0], height, channels)\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "# Convert string inputs to numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_set_encoded = label_encoder.fit_transform(train_set[\"Quality\"])\n",
    "test_set_encoded = label_encoder.transform(test_set[\"Quality\"])\n",
    "\n",
    "# show the classes in train_set[\"Quality\"]\n",
    "print(label_encoder.classes_)\n",
    "\n",
    "# summarize the classes of train_set_encoded and test_set_encoded\n",
    "# count the number of classes in train_set_encoded and test_set_encoded\n",
    "print(train_set_encoded)\n",
    "print(test_set_encoded)\n",
    "\n",
    "print(len(np.unique(train_set_encoded)))\n",
    "print(len(np.unique(test_set_encoded)))\n",
    "\n",
    "# One-hot encode the numerical labels\n",
    "onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "train_set_one_hot = onehot_encoder.fit_transform(train_set_encoded.reshape(-1, 1))\n",
    "test_set_one_hot = onehot_encoder.transform(test_set_encoded.reshape(-1, 1))\n",
    "\n",
    "# Check the number of classes in train_set_one_hot and test_set_one_hot\n",
    "print(train_set_one_hot[0])\n",
    "print(test_set_one_hot[0])\n",
    "\n",
    "# # fit the model using train_set_note_volumes and train_set_one_hot, but exclude the File Path, Quality, and Root Note columns\n",
    "model.fit(train_note_volumes.drop(columns=['Quality']), train_set_one_hot, epochs=3, batch_size=100)\n",
    "\n",
    "# # evaluate on test_set\n",
    "model.evaluate(test_note_volumes, test_set_one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>A#</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>C#</th>\n",
       "      <th>D</th>\n",
       "      <th>D#</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>F#</th>\n",
       "      <th>G</th>\n",
       "      <th>G#</th>\n",
       "      <th>Quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>dim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.007999</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.005141</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>maj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>0.00356</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.002209</td>\n",
       "      <td>0.002292</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.002329</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>aug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.008392</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.005519</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>aug</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A        A#         B         C        C#         D        D#  \\\n",
       "0   0.00003  0.000025  0.000018  0.000055  0.000036  0.000027  0.000013   \n",
       "1  0.000044  0.000055  0.000015  0.000029  0.000035  0.000057  0.000049   \n",
       "2  0.000499  0.000167  0.000135  0.007999  0.000137   0.00011  0.005141   \n",
       "3  0.000124  0.000125  0.002133   0.00356  0.000071  0.000068  0.002209   \n",
       "4  0.000223  0.000155  0.008392  0.000298  0.000249  0.000301    0.0052   \n",
       "\n",
       "          E         F        F#         G        G# Quality  \n",
       "0  0.000015  0.000025  0.000013  0.000023  0.000039     dim  \n",
       "1  0.000026  0.000057  0.000043  0.000023  0.000062     min  \n",
       "2  0.000042   0.00003  0.000057    0.0023  0.002004     maj  \n",
       "3  0.002292  0.000042  0.000077  0.002329  0.002155     aug  \n",
       "4  0.000319  0.000039  0.000159  0.005519  0.000599     aug  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalise the data so that the volum\n",
    "train_set_one_hot\n",
    "len(train_set_one_hot)\n",
    "train_note_volumes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.18566775244299674"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try running random forrests on the data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=0)\n",
    "rf.fit(train_note_volumes.drop(columns=['Quality']), train_set_one_hot)\n",
    "preds = rf.predict(test_note_volumes.drop(columns=['Quality']))\n",
    "print(preds)\n",
    "accuracy_score(test_set_one_hot, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adrianmcintosh/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/dense.py:73: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/adrianmcintosh/Library/Python/3.9/lib/python/site-packages/keras/src/optimizers/base_optimizer.py:31: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.2162 - loss: 1.3865\n",
      "Epoch 2/3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.2269 - loss: 1.3861\n",
      "Epoch 3/3\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2608 - loss: 1.3866 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x28c677640>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try running a neural network on the data\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=12))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_set.drop(columns=['File Path', 'Quality', 'Root Note', 'Octave', 'Inversion']), train_set_one_hot, epochs=3, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4755700325732899"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try running knn on the data\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(train_set_note_volumes.drop(columns=['File Path', 'Quality', 'Root Note']), train_set['Quality'])\n",
    "preds = knn.predict(test_set_note_volumes.drop(columns=['File Path', 'Quality', 'Root Note']))\n",
    "accuracy_score(test_set['Quality'], preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50814332247557"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for every chord quality, set it to 0, 1, 2, 3\n",
    "train_set['Quality'] = train_set['Quality'].replace(['maj', 'min', 'dim', 'aug'], [0, 1, 2, 3])\n",
    "test_set['Quality'] = test_set['Quality'].replace(['maj', 'min', 'dim', 'aug'], [0, 1, 2, 3])\n",
    "\n",
    "# try running xgboost on the data\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(train_set_note_volumes.drop(columns=['File Path', 'Quality', 'Root Note']), train_set['Quality'])\n",
    "preds = xgb.predict(test_set_note_volumes.drop(columns=['File Path', 'Quality', 'Root Note']))\n",
    "accuracy_score(test_set['Quality'], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19543973941368079"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try running a naive bayes classifier on the data\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(train_set_note_volumes.drop(columns=['File Path', 'Quality', 'Root Note']), train_set['Quality'])\n",
    "preds = gnb.predict(test_set_note_volumes.drop(columns=['File Path', 'Quality', 'Root Note']))\n",
    "accuracy_score(test_set['Quality'], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model.evaluate(test_reshaped, test_set_one_hot)[1]\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50814332247557"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try running xgboost on the data\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(train_set_note_volumes.drop(columns=['File Path', 'Quality', 'Root Note']), train_set['Quality'])\n",
    "preds = xgb.predict(test_set_note_volumes.drop(columns=['File Path', 'Quality', 'Root Note']))\n",
    "accuracy_score(test_set['Quality'], preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/adrianmcintosh/Desktop/UCLA/EC ENGR M146/Project/stage_3_cnn_classifier_part_1.ipynb Cell 20\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X31sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m lr\u001b[39m.\u001b[39mfit(train_set_note_volumes\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mFile Path\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mQuality\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mRoot Note\u001b[39m\u001b[39m'\u001b[39m]), train_set[\u001b[39m'\u001b[39m\u001b[39mQuality\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X31sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m preds \u001b[39m=\u001b[39m lr\u001b[39m.\u001b[39mpredict(test_set_note_volumes\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mFile Path\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mQuality\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mRoot Note\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X31sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m accuracy_score(test_set[\u001b[39m'\u001b[39;49m\u001b[39mQuality\u001b[39;49m\u001b[39m'\u001b[39;49m], preds)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    215\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:220\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \n\u001b[1;32m    156\u001b[0m \u001b[39mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39m0.5\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[39m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 220\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    221\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    222\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m     92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     95\u001b[0m             type_true, type_pred\n\u001b[1;32m     96\u001b[0m         )\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     99\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    100\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "# try linear regression on the data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(train_set_note_volumes.drop(columns=['File Path', 'Quality', 'Root Note']), train_set['Quality'])\n",
    "preds = lr.predict(test_set_note_volumes.drop(columns=['File Path', 'Quality', 'Root Note']))\n",
    "accuracy_score(test_set['Quality'], preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               File Path Root Note  Octave  Quality  Inversion\n",
      "0   data/chords/dim/Eb-7-dim-chord-1.wav        Eb       7        2          1\n",
      "3   data/chords/min/Bb-5-min-chord-0.wav        Bb       5        1          0\n",
      "20  data/chords/maj/Ab-3-maj-chord-1.wav        Ab       3        0          1\n",
      "28  data/chords/aug/Ab-2-aug-chord-0.wav        Ab       2        3          0\n",
      "32   data/chords/aug/G-4-aug-chord-1.wav         G       4        3          1\n",
      "          0         1         2         3         4         5         6  \\\n",
      "0  0.000030  0.000025  0.000018  0.000055  0.000036  0.000027  0.000013   \n",
      "1  0.000044  0.000055  0.000015  0.000029  0.000035  0.000057  0.000049   \n",
      "2  0.000499  0.000167  0.000135  0.007999  0.000137  0.000110  0.005141   \n",
      "3  0.000124  0.000125  0.002133  0.003560  0.000071  0.000068  0.002209   \n",
      "4  0.000223  0.000155  0.008392  0.000298  0.000249  0.000301  0.005200   \n",
      "\n",
      "          7         8         9        10        11  \\\n",
      "0  0.000015  0.000025  0.000013  0.000023  0.000039   \n",
      "1  0.000026  0.000057  0.000043  0.000023  0.000062   \n",
      "2  0.000042  0.000030  0.000057  0.002300  0.002004   \n",
      "3  0.002292  0.000042  0.000077  0.002329  0.002155   \n",
      "4  0.000319  0.000039  0.000159  0.005519  0.000599   \n",
      "\n",
      "                              File Path Quality Root Note  \n",
      "0  data/chords/dim/Eb-7-dim-chord-1.wav     dim        Eb  \n",
      "1                                   NaN     NaN       NaN  \n",
      "2                                   NaN     NaN       NaN  \n",
      "3  data/chords/min/Bb-5-min-chord-0.wav     min        Bb  \n",
      "4                                   NaN     NaN       NaN  \n",
      "                0           1           2           3           4           5  \\\n",
      "count  713.000000  713.000000  713.000000  713.000000  713.000000  713.000000   \n",
      "mean     0.001453    0.001869    0.001236    0.001039    0.001180    0.001139   \n",
      "std      0.004012    0.005431    0.002517    0.002013    0.002435    0.002095   \n",
      "min      0.000003    0.000005    0.000004    0.000006    0.000005    0.000003   \n",
      "25%      0.000048    0.000042    0.000040    0.000040    0.000034    0.000036   \n",
      "50%      0.000111    0.000107    0.000094    0.000107    0.000097    0.000095   \n",
      "75%      0.000560    0.000583    0.000645    0.000450    0.000639    0.000929   \n",
      "max      0.024434    0.032115    0.012638    0.009314    0.011039    0.009749   \n",
      "\n",
      "                6           7           8           9          10          11  \n",
      "count  713.000000  713.000000  713.000000  713.000000  713.000000  713.000000  \n",
      "mean     0.000948    0.000932    0.000782    0.000812    0.000686    0.000786  \n",
      "std      0.001653    0.001598    0.001352    0.001302    0.001172    0.001314  \n",
      "min      0.000006    0.000006    0.000007    0.000003    0.000003    0.000005  \n",
      "25%      0.000035    0.000033    0.000030    0.000031    0.000029    0.000030  \n",
      "50%      0.000088    0.000070    0.000061    0.000057    0.000058    0.000058  \n",
      "75%      0.000864    0.000971    0.001041    0.001377    0.001245    0.001447  \n",
      "max      0.007171    0.007057    0.006080    0.005639    0.006271    0.007292  \n"
     ]
    }
   ],
   "source": [
    "# print a summary of train_set\n",
    "print(train_set.head())\n",
    "print(train_set_note_volumes.head())\n",
    "\n",
    "# summarise note volumes\n",
    "print(train_set_note_volumes.describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
