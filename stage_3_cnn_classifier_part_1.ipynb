{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: CNN Classifier\n",
    "The manual approach, yielded some positive results\n",
    "Let's see if a machine learning algorithm using similar information might also work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plan:**\n",
    "\n",
    "Chord Qualities:\n",
    "1. Compute the summed frequency array, and note bin arrays\n",
    "2. Put these into a CNN (try different combinations)\n",
    "3. Try a few other models, including:\n",
    "    - random forest\n",
    "    - hmm\n",
    "    - knn\n",
    "\n",
    "Root Notes:\n",
    "1. Given the calculated quality and frequency volume, try to work out what the root note is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.io.wavfile import read as read_wav\n",
    "from scipy import fft,signal\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "TONE_A = 440 \n",
    "NOTES = ['A','A#','B','C','C#','D','D#','E','F','F#','G','G#'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_to_rnote(freq):\n",
    "    r = 12.0*np.log2(freq/TONE_A)\n",
    "    return r\n",
    "\n",
    "def rnote_to_freq(r):\n",
    "    f = TONE_A*2**(r/12)\n",
    "    return f\n",
    "\n",
    "def get_note_volume(rnote,fft_image,fft_freq,rnote_epsilon=0.2):\n",
    "    \"\"\" rnote - name or number of note,fft_image - fourier image of signal,\n",
    "    fft_freq - frequencies in fft_image,rnote_epsilon - halfwide of window to inspect\n",
    "    return maximum volume(magnitude) of signal in freq window for rnote \"\"\"\n",
    "    if isinstance(rnote,str):\n",
    "        rnote = NOTES.index(rnote)\n",
    "    try:\n",
    "        f0 = rnote_to_freq(rnote-rnote_epsilon)\n",
    "        f1 = rnote_to_freq(rnote+rnote_epsilon)\n",
    "        f_idx = np.where((fft_freq>=f0)&(fft_freq<=f1)) \n",
    "        maxVol = np.max((fft_image[f_idx]))\n",
    "    except Exception:\n",
    "        return 0.\n",
    "    \n",
    "    return maxVol\n",
    "\n",
    "def get_notes_volume(rnote,fft_image,fft_freq,rnote_epsilon=0.5,oct_range_from=-4.,oct_range_to=8.):\n",
    "    if isinstance(rnote,str):\n",
    "        rnote = NOTES.index(rnote)\n",
    "    rnotes = np.arange(rnote+12.*oct_range_from,rnote+12.*oct_range_to,12.0)\n",
    "    vol = []\n",
    "    for rn in rnotes:\n",
    "        vol.append(get_note_volume(rn,fft_image,fft_freq))\n",
    "        \n",
    "    return np.max(vol)\n",
    "\n",
    "def plot_notes(fileName):\n",
    "    \"\"\"convert the fft image from file to notes notations and plot on\"\"\"\n",
    "    #print(fileName)\n",
    "    rate,data_raw = read_wav(fileName)\n",
    "    data = (data_raw[:,0]+data_raw[:,1]).astype(np.float32) # stereo of any type -> mono of float32\n",
    "    data = minmax_scale(data,(-1.,1.)) \n",
    "    fft_image = np.abs(fft.rfft(data,norm='forward')) \n",
    "    fft_freq = fft.rfftfreq(len(data),1./rate)\n",
    "    vol_matrix = np.ndarray(shape=(12),dtype=np.float32)\n",
    "    for rnote in range(12):\n",
    "        vol_matrix[rnote] = get_notes_volume(rnote,fft_image,fft_freq)\n",
    "        \n",
    "    plt.bar(NOTES, vol_matrix)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    File Path Root Note  Octave Quality  \\\n",
      "0        data/chords/dim/Eb-7-dim-chord-1.wav        Eb       7     dim   \n",
      "1   data/chords/min7b5/C-3-min7b5-chord-1.wav         C       3  min7b5   \n",
      "2       data/chords/dim7/E-6-dim7-chord-0.wav         E       6    dim7   \n",
      "3        data/chords/min/Bb-5-min-chord-0.wav        Bb       5     min   \n",
      "4  data/chords/maj7_2/Ab-5-maj7_2-chord-0.wav        Ab       5  maj7_2   \n",
      "\n",
      "   Inversion  \n",
      "0          1  \n",
      "1          1  \n",
      "2          0  \n",
      "3          0  \n",
      "4          0  \n"
     ]
    }
   ],
   "source": [
    "# try it out on a few of the files in /data/train_set.csv:\n",
    "train_set = pd.read_csv('data/train_set.csv')\n",
    "test_set = pd.read_csv('data/test_set.csv')\n",
    "print(train_set.head())\n",
    "\n",
    "# remove the chords that are not maj or min in the Quality column\n",
    "train_set = train_set[train_set['Quality'].isin(['maj', 'min', 'dim', 'aug'])]\n",
    "test_set = test_set[test_set['Quality'].isin(['maj', 'min', 'dim', 'aug'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         File Path  Root Note  Octave  Inversion\n",
      "Quality                                         \n",
      "aug            179        179     179        179\n",
      "dim            178        178     178        178\n",
      "maj            178        178     178        178\n",
      "min            178        178     178        178\n",
      "         File Path  Root Note  Octave  Inversion\n",
      "Quality                                         \n",
      "aug             76         76      76         76\n",
      "dim             77         77      77         77\n",
      "maj             77         77      77         77\n",
      "min             77         77      77         77\n"
     ]
    }
   ],
   "source": [
    "print(train_set.groupby(['Quality']).count())\n",
    "print(test_set.groupby(['Quality']).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "713"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing:\n",
    "def preprocess(fileName):\n",
    "    rate, data_raw = read_wav(fileName)\n",
    "    data = (data_raw[:,0]+data_raw[:,1]).astype(np.float32) # stereo of any type -> mono of float32\n",
    "    data = minmax_scale(data,(-1.,1.))\n",
    "    fft_image = np.abs(fft.rfft(data,norm='forward'))\n",
    "    fft_freq = fft.rfftfreq(len(data),1./rate)\n",
    "    note_volumes = []\n",
    "    for note in NOTES:\n",
    "        note_volumes.append(get_note_volume(note,fft_image,fft_freq))\n",
    "    \n",
    "    return note_volumes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 713/713 [00:01<00:00, 420.28it/s]\n",
      "100%|██████████| 307/307 [00:00<00:00, 411.88it/s]\n"
     ]
    }
   ],
   "source": [
    "train_set_note_volumes = []\n",
    "test_set_note_volumes = []\n",
    "for i in tqdm(range(len(train_set))):\n",
    "    fileName = train_set['File Path'].iloc[i]\n",
    "    train_set_note_volumes.append(preprocess(fileName))\n",
    "\n",
    "for i in tqdm(range(len(test_set))):\n",
    "    fileName = test_set['File Path'].iloc[i]\n",
    "    test_set_note_volumes.append(preprocess(fileName))\n",
    "\n",
    "# save the new data to a csv, with some reference to the original data\n",
    "train_set_note_volumes = pd.DataFrame(train_set_note_volumes)\n",
    "train_set_note_volumes['File Path'] = train_set['File Path']\n",
    "train_set_note_volumes['Quality'] = train_set['Quality']\n",
    "# train_set_note_volumes['Chord'] = train_set['Chord']\n",
    "train_set_note_volumes['Root Note'] = train_set['Root Note']\n",
    "\n",
    "test_set_note_volumes = pd.DataFrame(test_set_note_volumes)\n",
    "test_set_note_volumes['File Path'] = test_set['File Path']\n",
    "test_set_note_volumes['Quality'] = test_set['Quality']\n",
    "# test_set_note_volumes['Chord'] = test_set['Chord']\n",
    "test_set_note_volumes['Root Note'] = test_set['Root Note']\n",
    "\n",
    "train_set_note_volumes.to_csv('data/train_set_note_volumes.csv')\n",
    "test_set_note_volumes.to_csv('data/test_set_note_volumes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               File Path Root Note  Octave Quality  Inversion  \\\n",
      "0   data/chords/dim/Eb-7-dim-chord-1.wav        Eb     7.0     dim        1.0   \n",
      "3   data/chords/min/Bb-5-min-chord-0.wav        Bb     5.0     min        0.0   \n",
      "20  data/chords/maj/Ab-3-maj-chord-1.wav        Ab     3.0     maj        1.0   \n",
      "28  data/chords/aug/Ab-2-aug-chord-0.wav        Ab     2.0     aug        0.0   \n",
      "32   data/chords/aug/G-4-aug-chord-1.wav         G     4.0     aug        1.0   \n",
      "\n",
      "    Note Volumes  \n",
      "0            NaN  \n",
      "3            NaN  \n",
      "20           NaN  \n",
      "28           NaN  \n",
      "32           NaN  \n"
     ]
    }
   ],
   "source": [
    "print(train_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.src.activations.activations'; 'keras.src.activations' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/adrianmcintosh/Desktop/UCLA/EC ENGR M146/Project/stage_3_cnn_classifier_part_1.ipynb Cell 13\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# run a CNN on the data, using the note volumes as the input and the chord quality as the output\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# Path: stage_3_cnn_classifier_part_2.ipynb\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Conv2D, MaxPooling2D, Flatten, Dense\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adrianmcintosh/Desktop/UCLA/EC%20ENGR%20M146/Project/stage_3_cnn_classifier_part_1.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m num_classes \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/__init__.py:8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[39mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39msince your modifications would be overwritten.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m _tf_keras\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m activations\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m applications\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/_tf_keras/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_tf_keras\u001b[39;00m \u001b[39mimport\u001b[39;00m keras\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/_tf_keras/keras/__init__.py:8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[39mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39msince your modifications would be overwritten.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m activations\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m applications\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m callbacks\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/keras/activations/__init__.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivations\u001b[39;00m \u001b[39mimport\u001b[39;00m get\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivations\u001b[39;00m \u001b[39mimport\u001b[39;00m serialize\n\u001b[0;32m---> 11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivations\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivations\u001b[39;00m \u001b[39mimport\u001b[39;00m elu\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivations\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivations\u001b[39;00m \u001b[39mimport\u001b[39;00m exponential\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivations\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivations\u001b[39;00m \u001b[39mimport\u001b[39;00m gelu\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.src.activations.activations'; 'keras.src.activations' is not a package"
     ]
    }
   ],
   "source": [
    "# run a CNN on the data, using the note volumes as the input and the chord quality as the output\n",
    "# Path: stage_3_cnn_classifier_part_2.ipynb\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "num_classes = 4\n",
    "height = 12\n",
    "width = 1\n",
    "channels = 1\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Add Convolutional layers\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(height, width, channels)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the output to feed into dense layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add Dense layers\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "train_reshaped = train_set[\"Note Volumes\"].reshape(train_set.shape[0], height, width, channels)\n",
    "test_reshaped = test_set[\"Note Volumes\"].reshape(train_set.shape[0], height, width, channels)\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "train_set_one_hot = to_categorical(train_set[\"Quality\"], num_classes)\n",
    "test_set_one_hot = to_categorical(test_set[\"Quality\"], num_classes)\n",
    "\n",
    "model.fit(train_reshaped, train_set_one_hot, epochs=3, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model.evaluate(test_reshaped, test_set_one_hot)[1]\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
